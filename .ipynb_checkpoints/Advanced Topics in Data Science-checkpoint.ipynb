{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Advanced Topics in Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions: Advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Best Practices for Writing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Docstrings\n",
    "\n",
    "Every docstring has some (although usually not all) of these five key pieces of information:\n",
    "\n",
    "- Description of what the function does.\n",
    "- Description of the arguments, if any.\n",
    "- Description of the return value(s), if any.\n",
    "- Description of errors raised, if any.\n",
    "- Optional extra notes or examples of usage.\n",
    "\n",
    "A docstring is a string written as the first line of a function. Because docstrings usually span multiple lines, they are enclosed in triple quotes, Python's way of writing multi-line strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_stack(df, new_names):\n",
    "    \"\"\"Splits a DataFrame's columns into two halves and then stack\n",
    "    them vertically, returning a new DataFrame with `new_names` as the\n",
    "    column names.\n",
    "\n",
    "    Args:\n",
    "      df (DataFrame): The DataFrame to split.\n",
    "      new_names (iterable of str): The column names for the new DataFrame.\n",
    "\n",
    "    Returns:\n",
    "      DataFrame\n",
    "    \"\"\"\n",
    "    half = int(len(df.columns) / 2)\n",
    "    left = df.iloc[:, :half]\n",
    "    right = df.iloc[:, half:]\n",
    "    return pd.DataFrame(\n",
    "      data=np.vstack([left.values, right.values]),\n",
    "      columns=new_names\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede acceder al docstring en jupyter con shit + tab en la función.\n",
    "\n",
    "También se puede acceder con el atributo \\__doc\\__ y con el módulo inspect.getdoc(función).\n",
    "\n",
    "El módulo inspect da una versión formateada más limpia.\n",
    "\n",
    "El módulo inspect tiene una [documentación](https://docs.python.org/3/library/inspect.html) sobre todos los métodos disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits a DataFrame's columns into two halves and then stack\n",
      "    them vertically, returning a new DataFrame with `new_names` as the\n",
      "    column names.\n",
      "\n",
      "    Args:\n",
      "      df (DataFrame): The DataFrame to split.\n",
      "      new_names (iterable of str): The column names for the new DataFrame.\n",
      "\n",
      "    Returns:\n",
      "      DataFrame\n",
      "    \n",
      "Splits a DataFrame's columns into two halves and then stack\n",
      "them vertically, returning a new DataFrame with `new_names` as the\n",
      "column names.\n",
      "\n",
      "Args:\n",
      "  df (DataFrame): The DataFrame to split.\n",
      "  new_names (iterable of str): The column names for the new DataFrame.\n",
      "\n",
      "Returns:\n",
      "  DataFrame\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "raw_docstring = split_and_stack.__doc__\n",
    "\n",
    "\n",
    "print(raw_docstring)\n",
    "\n",
    "\n",
    "formatted_docstring = inspect.getdoc(split_and_stack)\n",
    "\n",
    "\n",
    "print(formatted_docstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Estilos de docstring\n",
    "\n",
    "Hay varios estilos como Google style o Numpydoc. Nos centramos en Goofle por ser más compacto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(arg_1, arg_2=42):\n",
    "    \"\"\"Description of what the function does.\n",
    "\n",
    "    Args:\n",
    "      arg_1 (str): Description of arg_1 that can break onto the next line\n",
    "        if needed.\n",
    "      arg_2 (int, optional): Write optional when an argument has a default\n",
    "        value.\n",
    "\n",
    "    Returns:\n",
    "      bool: Optional description of the return value\n",
    "      Extra lines are not indented.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts the number of times `letter` appears in `content`.\n",
      "\n",
      "Args:\n",
      "    content (str)\n",
      "    letter (char)\n",
      "    \n",
      "Returns:\n",
      "    int\n"
     ]
    }
   ],
   "source": [
    "def count_letter(content, letter):\n",
    "    '''Counts the number of times `letter` appears in `content`.\n",
    "    \n",
    "    Args:\n",
    "        content (str)\n",
    "        letter (char)\n",
    "        \n",
    "    Returns:\n",
    "        int\n",
    "    '''\n",
    "    if (not isinstance(letter, str)) or len(letter) != 1:\n",
    "        raise ValueError('`letter` must be a single character string.')\n",
    "    return len([char for char in content if char == letter])\n",
    "\n",
    "\n",
    "formatted_docstring = inspect.getdoc(count_letter)\n",
    "print(formatted_docstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Información sobre errores\n",
    "\n",
    "Si hay avissos de error intencionados se añade el apartado Raises y las condiciones que lo ocasionan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts the number of times `letter` appears in `content`.\n",
      "\n",
      "Args:\n",
      "  content (str): The string to search.\n",
      "  letter (str): The letter to search for.\n",
      "\n",
      "Returns:\n",
      "  int\n",
      "  \n",
      "Raises:\n",
      "  ValueError: If `letter` is not a one-character string.\n"
     ]
    }
   ],
   "source": [
    "def count_letter(content, letter):\n",
    "    \"\"\"Counts the number of times `letter` appears in `content`.\n",
    "\n",
    "    Args:\n",
    "      content (str): The string to search.\n",
    "      letter (str): The letter to search for.\n",
    "\n",
    "    Returns:\n",
    "      int\n",
    "      \n",
    "    Raises:\n",
    "      ValueError: If `letter` is not a one-character string.\n",
    "    \"\"\"\n",
    "    if (not isinstance(letter, str)) or len(letter) != 1:\n",
    "        raise ValueError('`letter` must be a single character string.')\n",
    "    return len([char for char in content if char == letter])\n",
    "\n",
    "\n",
    "formatted_docstring = inspect.getdoc(count_letter)\n",
    "print(formatted_docstring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Don't Repeat Yourself (DRY) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpas = pd.DataFrame(np.random.uniform(0,4,size=(100, 4)) , columns = ['y1_gpa','y2_gpa','y3_gpa','y4_gpa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y1_gpa</th>\n",
       "      <th>y2_gpa</th>\n",
       "      <th>y3_gpa</th>\n",
       "      <th>y4_gpa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.143823</td>\n",
       "      <td>3.273296</td>\n",
       "      <td>2.294024</td>\n",
       "      <td>2.963300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.499787</td>\n",
       "      <td>1.847920</td>\n",
       "      <td>2.971409</td>\n",
       "      <td>2.787090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.284193</td>\n",
       "      <td>2.163405</td>\n",
       "      <td>1.384538</td>\n",
       "      <td>1.021901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.571584</td>\n",
       "      <td>0.784123</td>\n",
       "      <td>3.043326</td>\n",
       "      <td>1.291948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.731383</td>\n",
       "      <td>0.496277</td>\n",
       "      <td>1.709457</td>\n",
       "      <td>0.150069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y1_gpa    y2_gpa    y3_gpa    y4_gpa\n",
       "0  2.143823  3.273296  2.294024  2.963300\n",
       "1  0.499787  1.847920  2.971409  2.787090\n",
       "2  1.284193  2.163405  1.384538  1.021901\n",
       "3  1.571584  0.784123  3.043326  1.291948\n",
       "4  3.731383  0.496277  1.709457  0.150069"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(df, column):\n",
    "    '''Normalizes calculation z score of a column in the given df\n",
    "    \n",
    "    Args:\n",
    "        df (pd.Dataframe): The dataframe in which we apply the function\n",
    "        column (pd.Series): The column to Normalizes\n",
    "        \n",
    "    Returns:\n",
    "        pd.Dataframe\n",
    "        \n",
    "    Raises:\n",
    "        nothing\n",
    "    '''\n",
    "    df[column[:2] + '_z'] = (df[column] - df[column].mean()) / df[column].std()\n",
    "    return df\n",
    "   \n",
    "\n",
    "for col in ['y1_gpa','y2_gpa','y3_gpa','y4_gpa']:    \n",
    "    gpas = standardize(gpas,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y1_gpa</th>\n",
       "      <th>y2_gpa</th>\n",
       "      <th>y3_gpa</th>\n",
       "      <th>y4_gpa</th>\n",
       "      <th>y1_z</th>\n",
       "      <th>y2_z</th>\n",
       "      <th>y3_z</th>\n",
       "      <th>y4_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.143823</td>\n",
       "      <td>3.273296</td>\n",
       "      <td>2.294024</td>\n",
       "      <td>2.963300</td>\n",
       "      <td>0.017830</td>\n",
       "      <td>1.191054</td>\n",
       "      <td>0.366668</td>\n",
       "      <td>0.820350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.499787</td>\n",
       "      <td>1.847920</td>\n",
       "      <td>2.971409</td>\n",
       "      <td>2.787090</td>\n",
       "      <td>-1.340849</td>\n",
       "      <td>-0.043566</td>\n",
       "      <td>0.964222</td>\n",
       "      <td>0.666739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.284193</td>\n",
       "      <td>2.163405</td>\n",
       "      <td>1.384538</td>\n",
       "      <td>1.021901</td>\n",
       "      <td>-0.692594</td>\n",
       "      <td>0.229698</td>\n",
       "      <td>-0.435633</td>\n",
       "      <td>-0.872073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.571584</td>\n",
       "      <td>0.784123</td>\n",
       "      <td>3.043326</td>\n",
       "      <td>1.291948</td>\n",
       "      <td>-0.455085</td>\n",
       "      <td>-0.964995</td>\n",
       "      <td>1.027663</td>\n",
       "      <td>-0.636658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.731383</td>\n",
       "      <td>0.496277</td>\n",
       "      <td>1.709457</td>\n",
       "      <td>0.150069</td>\n",
       "      <td>1.329836</td>\n",
       "      <td>-1.214320</td>\n",
       "      <td>-0.149007</td>\n",
       "      <td>-1.632096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     y1_gpa    y2_gpa    y3_gpa    y4_gpa      y1_z      y2_z      y3_z  \\\n",
       "0  2.143823  3.273296  2.294024  2.963300  0.017830  1.191054  0.366668   \n",
       "1  0.499787  1.847920  2.971409  2.787090 -1.340849 -0.043566  0.964222   \n",
       "2  1.284193  2.163405  1.384538  1.021901 -0.692594  0.229698 -0.435633   \n",
       "3  1.571584  0.784123  3.043326  1.291948 -0.455085 -0.964995  1.027663   \n",
       "4  3.731383  0.496277  1.709457  0.150069  1.329836 -1.214320 -0.149007   \n",
       "\n",
       "       y4_z  \n",
       "0  0.820350  \n",
       "1  0.666739  \n",
       "2 -0.872073  \n",
       "3 -0.636658  \n",
       "4 -1.632096  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Do One Thing\n",
    "\n",
    "Por modularidad y simplicidad es mejor que las funciones hagan una cosa si es posible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INITIAL CODE\n",
    "def mean_and_median(values):\n",
    "    \"\"\"Gets the mean and median of a list of `values`\n",
    "\n",
    "    Args:\n",
    "      values (iterable of float): A list of numbers\n",
    "\n",
    "    Returns:\n",
    "      tuple (float, float): The mean and median\n",
    "    \"\"\"\n",
    "    mean = sum(values) / len(values)\n",
    "    midpoint = int(len(values) / 2)\n",
    "    if len(values) % 2 == 0:\n",
    "        median = (values[midpoint - 1] + values[midpoint]) / 2\n",
    "    else:\n",
    "        median = values[midpoint]\n",
    "\n",
    "    return mean, median\n",
    "\n",
    "\n",
    "def find_mean(values):\n",
    "    \"\"\"Gets the mean of a list of `values`\n",
    "\n",
    "    Args:\n",
    "      values (iterable of float): A list of numbers\n",
    "\n",
    "    Returns:\n",
    "       (float): The mean\n",
    "    \"\"\"\n",
    "    return sum(values)/len(values)\n",
    "\n",
    "\n",
    "def find_median(values):\n",
    "    \"\"\"Gets the median of a list of `values`\n",
    "\n",
    "    Args:\n",
    "    values (iterable of float): A list of numbers\n",
    "\n",
    "    Returns:\n",
    "    (float): The median\n",
    "    \"\"\"\n",
    "    midpoint = int(len(values) / 2)\n",
    "    if len(values) % 2 == 0:\n",
    "        median = (values[midpoint - 1] + values[midpoint]) / 2\n",
    "    else:\n",
    "        median = values[midpoint] \n",
    "        \n",
    "    return median\n",
    "\n",
    "        \n",
    "list_mean = find_mean([1,2,3])\n",
    "\n",
    "list_median = find_median([1,2,3,4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pass by  Assignment\n",
    "\n",
    "Las listas son objetos **mutables** y cunado se pasan como argumento se pueden modificar.\n",
    "\n",
    "Los integers son **inmutables**, por lo que no se modifican cuando se pasan como argumentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n",
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "b = a\n",
    "\n",
    "a.append(4)\n",
    "\n",
    "print(b)\n",
    "\n",
    "b.append(5)\n",
    "\n",
    "print(a)\n",
    "\n",
    "a = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que hace es poner b en la misma dirdección de memoria que a, y luego al asignar un int a \"a\", el b sigue en la misma dirección.\n",
    "\n",
    "![title](imagenes/mem_dir_1.PNG)\n",
    "\n",
    "![title](imagenes/mem_dir_2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Immutable\n",
    "\n",
    "- int\n",
    "- float\n",
    "- bool\n",
    "- string\n",
    "- bytes\n",
    "- tuple\n",
    "- frozenset\n",
    "\n",
    "###### Mutable\n",
    "\n",
    "- list\n",
    "- dict\n",
    "- set\n",
    "- bytearray\n",
    "- objects\n",
    "- functions\n",
    "- almost everything else!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Problemas con la mutabilidad de los argumentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def foo(var=[]):\n",
    "    var.append(1)\n",
    "    return var\n",
    "\n",
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El argumento por defecto ya ha sido mdoificado la primera vez que se ha llamado.\n",
    "\n",
    "Para evitarlo es mejor hacer los argumentos inmutables poniendo valor por defecto None y crearlos en la función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def foo(var=None):\n",
    "    if var is None:\n",
    "        var = []\n",
    "    var.append(1)\n",
    "    return var\n",
    "\n",
    "foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El equivalente pero con DataFrames:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column(values, df = None):\n",
    "    \"\"\"Adds a column of `values` to a DataFrame `df`.\n",
    "    The column will be named \"col_<n>\" where \"n\" is\n",
    "    the numerical index of the column.\n",
    "\n",
    "    Args:\n",
    "        values (iterable): The values of the new column\n",
    "        df (DataFrame, optional): The DataFrame to update.\n",
    "          If no DataFrame is passed, one is created by default.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame\n",
    "    \"\"\"\n",
    "    if df == None:\n",
    "        df = pd.DataFrame()\n",
    "        \n",
    "    df['col_{}'.format(len(df.columns))] = values\n",
    "    return df\n",
    "\n",
    "\n",
    "df_1 = add_column(values = range(10))\n",
    "\n",
    "df_2 = add_column(values = range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Managers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los context managers son un **tipo de función** que establece un contexto, ejecuta el código y luego elimina el contexto.\n",
    "\n",
    "Tienen la capacidad de devolver el control y acabar de ejecutarse después.\n",
    "\n",
    "Por ejemplo la función open() es un context manager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Este es el texto de mi archivo.\n",
      "^;..;^\n"
     ]
    }
   ],
   "source": [
    "with open('my_file.txt') as my_file:\n",
    "    text = my_file.read()\n",
    "    \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La keyword de los context managers: with\n",
    "\n",
    "````\n",
    "with <context-manager>(<args>) as <variable-name>:\n",
    "  # Run your code here\n",
    "  # This code is running \"inside the context\"\n",
    "\n",
    "# This code runs after the context is removed\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lewis Caroll uses the word \"cat\" 24 times\n"
     ]
    }
   ],
   "source": [
    "with open('alice_in_wonderland.txt') as file:\n",
    "    text = file.read()\n",
    "    n = 0\n",
    "    for word in text.split():\n",
    "        if word.lower() in ['cat', 'cats']:\n",
    "            n += 1\n",
    "\n",
    "print('Lewis Caroll uses the word \"cat\" {} times'.format(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definir un Context Manager\n",
    "\n",
    "Hay dos maneras:\n",
    "\n",
    "- By using a class that has special __enter__() and __exit__() methods\n",
    "- By decorating a certain kind of function   \n",
    "\n",
    "Si nos centramos en la segunda hay 5 partes:\n",
    "\n",
    "- Define a function.\n",
    "- (optional) Add any setup code your context needs.\n",
    "- Use the yield keyword to signal to Python that this is a special kind of function.\n",
    "- (optional) Add any teardown code needed to clean up the context.\n",
    "- Add the @contextlib.contextmanager decorator.\n",
    "\n",
    "\n",
    "````\n",
    "@contextlib.contextmanager\n",
    "def my_context():\n",
    "  # Add any set up code you need\n",
    "\n",
    "  yield\n",
    "\n",
    "  # Add any teardown code you need\n",
    "\n",
    "\n",
    "````\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "foo is 42\n",
      "goodbye\n"
     ]
    }
   ],
   "source": [
    "@contextlib.contextmanager\n",
    "def my_context():\n",
    "    print('hello')\n",
    "\n",
    "    yield 42\n",
    "\n",
    "    print('goodbye')\n",
    "    \n",
    "    \n",
    "with my_context() as foo:\n",
    "    print('foo is {}'.format(foo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los context manager no tiene por qué devolver un valor, por ejemplo este cambia el directorio de trabajo y luego lo cambia al original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] El sistema no puede encontrar la ruta especificada: '/data/project_1/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-2ab25fef67a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0min_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/data/project_1/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mproject_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-64-2ab25fef67a7>\u001b[0m in \u001b[0;36min_dir\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# switch to new working directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32myield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] El sistema no puede encontrar la ruta especificada: '/data/project_1/'"
     ]
    }
   ],
   "source": [
    "import os \n",
    "@contextlib.contextmanager\n",
    "def in_dir(path):\n",
    "    # save current working directory\n",
    "    old_dir = os.getcwd()\n",
    "\n",
    "    # switch to new working directory\n",
    "    os.chdir(path)\n",
    "\n",
    "    yield\n",
    "\n",
    "    # change back to previous\n",
    "    # working directory\n",
    "    os.chdir(old_dir)\n",
    "    \n",
    "with in_dir('/data/project_1/'):\n",
    "    project_files = os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should take approximately 2 seconds\n",
      "Elapsed: 2.01s\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import time\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def timer():\n",
    "    \"\"\"Time the execution of a context block.\n",
    "\n",
    "    Yields:\n",
    "      None\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    # Send control back to the context block\n",
    "    yield\n",
    "    end = time.time()\n",
    "    print('Elapsed: {:.2f}s'.format(end - start))\n",
    "\n",
    "with timer():\n",
    "    print('This should take approximately 2 seconds')\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yield control y acabar de ejecutar después\n",
    "\n",
    "Ejemplo de conexión a una base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'postgres'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-dcf945cb4e2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpostgres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# set up database connection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpostgres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'postgres'"
     ]
    }
   ],
   "source": [
    "@contextlib.contextmanager\n",
    "def database(url):\n",
    "    # set up database connection\n",
    "    db = postgres.connect(url)\n",
    "\n",
    "    yield db\n",
    "\n",
    "    # tear down database connection\n",
    "    db.disconnect()\n",
    "    \n",
    "url = 'http://dataquest.io/data'\n",
    "with database(url) as my_db:\n",
    "    course_list = my_db.execute(\n",
    "      'SELECT * FROM courses'\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, si quiero asegurarme de que no modifico para nada un archivo, se puede usar un context manager para abrir, copiar y cerrar el archivo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Este es el texto de mi archivo.\n",
      "^;..;^\n"
     ]
    }
   ],
   "source": [
    "@contextlib.contextmanager\n",
    "def open_read_only(filename):\n",
    "    read_only_file = open(filename, mode='r')\n",
    "    \n",
    "    yield read_only_file\n",
    "    \n",
    "    read_only_file.close()\n",
    "    \n",
    "    \n",
    "with open_read_only('my_file.txt') as my_file:\n",
    "    text = my_file.read()\n",
    "    print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context Managers anidados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El contexto creado dentro de otro tiene acceso a los objetos del contexto de nivel superior.\n",
    "\n",
    "Ejemplo de copiar contenido de un archivo a otro. Se puede hacer copaindo el archivo completo directamente, pero se puede dar el caso de no tener suficeinte memoria para hacerlo. Otra forma sería aprovechar que un archivo es un objeto en el que se puede iterar línea a línea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy(src, dst):\n",
    "    \"\"\"Copy the contents of one file to another.\n",
    "\n",
    "    Args:\n",
    "      src (str): File name of the file to be copied.\n",
    "      dst (str): Where to write the new file.\n",
    "    \"\"\"\n",
    "    # Open both files\n",
    "    with open(src) as f_src:\n",
    "        with open(dst, 'w') as f_dst:\n",
    "            # Read and write each line, one at a time\n",
    "            for line in f_src:\n",
    "                f_dst.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro ejemplo de acceder a una API o similar y copiar contenido:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stock' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-c7f09e3fdd0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mstock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NVDA'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnvda\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NVDA.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf_out\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m               \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnvda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m               \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Logging ${:.2f} for NVDA'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stock' is not defined"
     ]
    }
   ],
   "source": [
    "with stock('NVDA') as nvda:\n",
    "    with open('NVDA.txt','w') as f_out:\n",
    "        for _ in range(10):\n",
    "              value = nvda.price()\n",
    "              print('Logging ${:.2f} for NVDA'.format(value))\n",
    "              f_out.write('{:.2f}\\n'.format(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gestión de errores dentro del Context Manager\n",
    "\n",
    "Si hay un error con un recurso abierto el recurso no se va a liberar, lo que puede ocasionar problemas.\n",
    "\n",
    "Por eso es importante escribir el código del contexto utilizando try, except y finally.\n",
    "\n",
    "````\n",
    "try:\n",
    "  # code that might raise an error\n",
    "except:\n",
    "  # do something about the error\n",
    "finally:\n",
    "  # this code runs no matter what\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cuándo se deberían utilizar Context Managers\n",
    "\n",
    "Cuando encontremos estos patrones:\n",
    "\n",
    "- OPEN/CLOSE\n",
    "- LOCK/RELEASE\n",
    "- CHANGE/RESET\n",
    "- ENTER/EXIT\n",
    "- START/STOP\n",
    "- SETUP/TEARDOWN\n",
    "- CONNECT/DISCONNECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction To Decorators\n",
    "\n",
    "Es una forma de modificar el funcionamiento de funciones.\n",
    "\n",
    "Para comprender el efecto de los decorators hay que recordar conceptos como:\n",
    "\n",
    "- Functions as objects\n",
    "- Nested functions\n",
    "- Nonlocal scope\n",
    "- Closures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions as Objects\n",
    "\n",
    "Las funciones en Python son como cualquier otro obketo. Se pueden asignar a variables, meter en listas, diccionarios, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_function():\n",
    "    print('Hello')\n",
    "    \n",
    "x = my_function\n",
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.my_function()>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am printing with an element of a list!\n"
     ]
    }
   ],
   "source": [
    "list_of_functions = [my_function, open, print]\n",
    "list_of_functions[2]('I am printing with an element of a list!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested FUnctions\n",
    "\n",
    "Se pueden definir funcionesdentro de otras: funciones anudadas, internas, helper, child,.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(x, y):\n",
    "    def in_range(v):\n",
    "        return v > 4 and v < 10\n",
    "\n",
    "    if in_range(x) and in_range(y):\n",
    "        print(x * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pueden devolver funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_function():\n",
    "    def print_me(s):\n",
    "        print(s)\n",
    "\n",
    "    return print_me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 + 2 = 7\n",
      "5 - 2 = 3\n"
     ]
    }
   ],
   "source": [
    "def create_math_function(func_name):\n",
    "    if func_name == 'add':\n",
    "        def add(a, b):\n",
    "            return a + b\n",
    "        return add\n",
    "    elif func_name == 'subtract':\n",
    "        # Define the subtract() function\n",
    "        def subtract(a,b):\n",
    "            return a - b\n",
    "        return subtract\n",
    "   \n",
    "\n",
    "    else:\n",
    "        print(\"I don't know that one\")\n",
    "    \n",
    "add = create_math_function('add')\n",
    "print('5 + 2 = {}'.format(add(5, 2)))\n",
    "\n",
    "subtract = create_math_function('subtract')\n",
    "print('5 - 2 = {}'.format(subtract(5, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nonlocal Scope\n",
    "\n",
    "El orden en el que python mira la existencia de una variable es: local, nonlocal, global y builtin.\n",
    "\n",
    "EL non local scope es el scope de la función padre de la función en la que se ha llamado.\n",
    "\n",
    "![](imagenes/nonlocal_scope.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede modificar una variable global dentro de una función declarándola dentro de la función con global.\n",
    "\n",
    "Igualmente se puede hacer lo mismo con una nonlocal.\n",
    "\n",
    "No es una práctica muy buena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "30\n",
      "2\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "x = 50\n",
    "\n",
    "def one():\n",
    "    x = 10\n",
    "\n",
    "def two():\n",
    "    global x\n",
    "    x = 30\n",
    "  \n",
    "def three():\n",
    "    x = 100\n",
    "    def four():\n",
    "        nonlocal x\n",
    "        x = 2\n",
    "    four()\n",
    "    print(x)\n",
    "     \n",
    "\n",
    "for func in [one, two, three]:\n",
    "    func()\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Closures\n",
    "\n",
    "Son tuplos de variables que no van a estar en el scope, pero que una función necesita para correr. Por ejemplo, cómo sabe func() sobre el valor de 'a'? Porque al el valor 5 se queda en el \\_\\_closure__ de bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo():\n",
    "    a = 5\n",
    "    def bar():\n",
    "        print(a)\n",
    "    return bar\n",
    "\n",
    "func = foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(func.__closure__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func.__closure__[0].cell_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "def return_a_func(arg1, arg2):\n",
    "    def new_func():\n",
    "        print('arg1 was {}'.format(arg1))\n",
    "        print('arg2 was {}'.format(arg2))\n",
    "    return new_func\n",
    "    \n",
    "my_func = return_a_func(2, 17)\n",
    "\n",
    "print(len(my_func.__closure__))\n",
    "\n",
    "print(my_func.__closure__[0].cell_contents)\n",
    "\n",
    "print(my_func.__closure__[1].cell_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque se elimine o sobreescriba una variable que se haya guardado en el closure de una función, al estar ahí guardado, el valor sigue estando disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "x = 25\n",
    "\n",
    "def foo(value):\n",
    "    def bar():\n",
    "        print(value)\n",
    "    return bar\n",
    "\n",
    "my_func = foo(x)\n",
    "del(x)\n",
    "my_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "x = 25\n",
    "\n",
    "def foo(value):\n",
    "    def bar():\n",
    "        print(value)\n",
    "    return bar\n",
    "\n",
    "x = foo(x)\n",
    "\n",
    "x()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are running my_special_function()\n"
     ]
    }
   ],
   "source": [
    "def my_special_function():\n",
    "    print('You are running my_special_function()')\n",
    "\n",
    "def get_new_func(func):\n",
    "    def call_func():\n",
    "        func()\n",
    "    return call_func\n",
    "\n",
    "new_func = get_new_func(my_special_function)\n",
    "\n",
    "# Rewrite my_special_function() here\n",
    "def my_special_function():\n",
    "    print('hello')\n",
    "    \n",
    "new_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decorators\n",
    "\n",
    "Teniendo en cuenta las propiedades que hemos visto de las funciones:\n",
    "\n",
    "- Functions as objects: Because functions are objects, they can be passed around as variables.\n",
    "- Nested functions: A function defined inside another function.\n",
    "- Nonlocal variables: Variables defined in the parent function that are used by the child function.\n",
    "- Closures: Nonlocal variables attached to a returned function.\n",
    "\n",
    "Un Decorator es un wrapper que ponemos alrededor de una función y cambia su comportamiento, cogen una función como argumento y devuelve una versión modificada:\n",
    "\n",
    "![](imagenes/decorators.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, un decorador que duplica los argumentos de una función:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@double_args\n",
    "def multiply(a, b):\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo hacemos con funciones anidadas sería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiply(a, b):\n",
    "    return a * b\n",
    "\n",
    "def double_args(func):\n",
    "    def wrapper(a, b):\n",
    "        # Call the passed in function, but double each argument\n",
    "        return func(2*a, 2*b)\n",
    "    return wrapper\n",
    "\n",
    "new_multiply = double_args(multiply)\n",
    "\n",
    "new_multiply(1,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código de la izquierda hace exactamente lo mismo que el de la derecha:\n",
    "\n",
    "![title](imagenes/decorators_2.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_function was called with a=1, b=2, c=3\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "def print_args(func):\n",
    "    sig = inspect.signature(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        bound = sig.bind(*args, **kwargs).arguments\n",
    "        str_args = ', '.join(['{}={}'.format(k, v) for k, v in bound.items()])\n",
    "        print('{} was called with {}'.format(func.__name__, str_args))\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "@print_args\n",
    "def my_function(a, b, c):\n",
    "    print(a + b + c)\n",
    "    \n",
    "my_function(1,2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decorators: Advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplos reales de decoradores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memoizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos hacer un decorator que guarde en cache valores de llamadas anteriores a una función. Esto es **Memoize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memoize(func):\n",
    "    \"\"\"Store the results of the decorated function for fast lookup\n",
    "    \"\"\"\n",
    "\n",
    "    # Store results in a dict that maps arguments to results\n",
    "    cache = {}\n",
    "\n",
    "    def wrapper(*args, **kwargs):\n",
    "        keys = (args, tuple(kwargs.items()))\n",
    "        # If these arguments haven't been seen before, call func() and store the result.\n",
    "        if keys not in cache:\n",
    "            cache[keys] = func(*args, **kwargs)\n",
    "        return cache[keys]\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "import time\n",
    "\n",
    "@memoize\n",
    "def slow_function(a, b):\n",
    "    print('Sleeping...')\n",
    "    time.sleep(5)\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sleeping...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_function(3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_function(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Número de llamadas a una función\n",
    "\n",
    "Otra aplicación de decoradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'function'>\n",
      "calling foo()\n",
      "<class 'function'>\n",
      "calling foo()\n",
      "foo() was called 2 times.\n"
     ]
    }
   ],
   "source": [
    "def counter(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        wrapper.count += 1        \n",
    "        # Call the function being decorated and return the result\n",
    "        return func(*args, **kwargs)\n",
    "    wrapper.count = 0\n",
    "    # Return the new decorated function\n",
    "    return wrapper\n",
    "\n",
    "@counter\n",
    "def foo():\n",
    "    print('calling foo()')    \n",
    "\n",
    "foo()\n",
    "foo()\n",
    "\n",
    "print('foo() was called {} times.'.format(foo.count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tiempo de ejecución de función"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sleep_n_seconds took 5.004520416259766s\n"
     ]
    }
   ],
   "source": [
    "def timer(func):\n",
    "    \"\"\"A decorator that prints how long a function took to run.\"\"\"\n",
    "\n",
    "    # Define the wrapper function to return.\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # When wrapper() is called, get the current time.\n",
    "        t_start = time.time()\n",
    "\n",
    "        # Call the decorated function and store the result.\n",
    "        result = func(*args, **kwargs)\n",
    "\n",
    "        # Get the total time it took to run, and print it.\n",
    "        t_total = time.time() - t_start\n",
    "\n",
    "        print('{} took {}s'.format(func.__name__, t_total))        \n",
    "        return result\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "@timer\n",
    "def sleep_n_seconds(n):\n",
    "    time.sleep(n)\n",
    "    \n",
    "sleep_n_seconds(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imprimir el tipo del resultado de una función "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo() returned type <class 'int'>\n",
      "42\n",
      "foo() returned type <class 'list'>\n",
      "[1, 2, 3]\n",
      "foo() returned type <class 'dict'>\n",
      "{'a': 42}\n"
     ]
    }
   ],
   "source": [
    "def print_return_type(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        result = func(*args, **kwargs)\n",
    "        print('{}() returned type {}'.format(func.__name__, type(result)))\n",
    "        return result\n",
    "    return wrapper\n",
    "       \n",
    "@print_return_type\n",
    "def foo(value):\n",
    "    return value\n",
    "\n",
    "print(foo(42))\n",
    "print(foo([1, 2, 3]))\n",
    "print(foo({'a': 42}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problemas con los decoradores y los metadatos de las funciones\n",
    "\n",
    "Los decoradores alteran los metadatos de las funciones, como los valores por defecto, la docstring, el nombre, .. ya que devuelven lo del wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pause processing for n seconds.\n",
      "\n",
      "    Args:\n",
      "        n (int): The number of seconds to pause for.\n",
      "    \n",
      "sleep_n_seconds\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "def sleep_n_seconds(n=10):\n",
    "    \"\"\"Pause processing for n seconds.\n",
    "\n",
    "    Args:\n",
    "        n (int): The number of seconds to pause for.\n",
    "    \"\"\"\n",
    "    time.sleep(n)\n",
    "    \n",
    "    \n",
    "print(sleep_n_seconds.__doc__)\n",
    "print(sleep_n_seconds.__name__)\n",
    "print(sleep_n_seconds.__defaults__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "wrapper\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def timer(func):\n",
    "    \"\"\"A decorator that prints how long a function took to run.\"\"\"  \n",
    "    def wrapper(*args, **kwargs):\n",
    "        t_start = time.time()\n",
    "    \n",
    "        result = func(*args, **kwargs)\n",
    "    \n",
    "        t_total = time.time() - t_start\n",
    "        print('{} took {}s'.format(func.__name__, t_total))\n",
    "    \n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timer\n",
    "def sleep_n_seconds(n=10):\n",
    "    \"\"\"Pause processing for n seconds.\n",
    "  \n",
    "    Args:\n",
    "        n (int): The number of seconds to pause for.\n",
    "    \"\"\"\n",
    "    time.sleep(n)\n",
    "    \n",
    "print(sleep_n_seconds.__doc__)\n",
    "print(sleep_n_seconds.__name__)\n",
    "print(sleep_n_seconds.__defaults__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto se puede solucionar importando la función wraps de functools, que es un decorador que admite argumentos. Modifica los metadatos de wrapper para que sean los de la función decorada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pause processing for n seconds.\n",
      "  \n",
      "    Args:\n",
      "        n (int): The number of seconds to pause for.\n",
      "    \n",
      "sleep_n_seconds\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "\n",
    "def timer(func):\n",
    "    \"\"\"A decorator that prints how long a function took to run.\"\"\"\n",
    "\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        t_start = time.time()\n",
    "\n",
    "        result = func(*args, **kwargs)\n",
    "\n",
    "        t_total = time.time() - t_start\n",
    "        print('{} took {}s'.format(func.__name__, t_total))\n",
    "\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@timer\n",
    "def sleep_n_seconds(n=10):\n",
    "    \"\"\"Pause processing for n seconds.\n",
    "  \n",
    "    Args:\n",
    "        n (int): The number of seconds to pause for.\n",
    "    \"\"\"\n",
    "    time.sleep(n)\n",
    "\n",
    "    \n",
    "print(sleep_n_seconds.__doc__)\n",
    "print(sleep_n_seconds.__name__)\n",
    "print(sleep_n_seconds.__defaults__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro ejemplo de wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "30\n",
      "Adds two numbers and prints the sum\n"
     ]
    }
   ],
   "source": [
    "from functools import wraps\n",
    "def add_hello(func):\n",
    "    # Decorate wrapper() so that it keeps func()'s metadata\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        \"\"\"Print 'hello' and then call the decorated function.\"\"\"\n",
    "        print('Hello')\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "@add_hello\n",
    "def print_sum(a, b):\n",
    "    \"\"\"Adds two numbers and prints the sum\"\"\"\n",
    "    print(a + b)\n",
    "    \n",
    "    \n",
    "print_sum(10,20)\n",
    "print(print_sum.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoradores con agumentos\n",
    "\n",
    "Para poner argumentos en decoradores lo que hay que hacer es meter el decorador en una fucnión que devuelva ese decorador y que tenga los argumentos que necesitamos para que se encuentren en el scope del decorador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "Hello!\n",
      "Hello!\n",
      "Hello!\n",
      "Hello!\n",
      "Hello!\n"
     ]
    }
   ],
   "source": [
    "def run_n_times(n):\n",
    "    \"\"\"Define and return a decorator\"\"\"\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            for i in range(n):\n",
    "                func(*args, **kwargs)\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@run_n_times(3)\n",
    "def print_sum(a, b):\n",
    "    print(a + b)\n",
    "    \n",
    "print_sum(3,5)\n",
    "    \n",
    "@run_n_times(5)\n",
    "def print_hello():\n",
    "    print('Hello!')\n",
    "    \n",
    "print_hello()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo de decorador con argumentos: Timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fucnión signal() led ice a python que cuando vea al señal que es signalnum, llamar a la handler function. En este caso le decimos que llame a araise_timeout() cuando vea la alarma\n",
    "````\n",
    "# When an \"alarm\" signal goes off, call raise_timeout()\n",
    "signal.signal(signalnum=signal.SIGALRM, handler=raise_timeout)\n",
    "````\n",
    "\n",
    "La función alarm() nos deja poner una aalrma dentro de unos seguntos yse cancela con parámetro cero.\n",
    "````\n",
    "# Set off an alarm in 5 seconds\n",
    "signal.alarm(5)\n",
    "\n",
    "# Cancel the alarm\n",
    "signal.alarm(0)\n",
    "````\n",
    "\n",
    "La fución siguiente salta una alarma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'signal' has no attribute 'alarm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-8a504d7bf0dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'foo!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mfoo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-8a504d7bf0dc>\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m# Set an alarm for 5 seconds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0msignal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malarm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;31m# Call the decorated func\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'signal' has no attribute 'alarm'"
     ]
    }
   ],
   "source": [
    "def timeout_in_5s(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # Set an alarm for 5 seconds\n",
    "        signal.alarm(5)\n",
    "        try:\n",
    "            # Call the decorated func\n",
    "            return func(*args, **kwargs)\n",
    "        finally:\n",
    "            # Cancel alarm\n",
    "            signal.alarm(0)\n",
    "    return wrapper\n",
    "\n",
    "@timeout_in_5s\n",
    "def foo():\n",
    "    time.sleep(10)\n",
    "    print('foo!')\n",
    "    \n",
    "foo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta función más útil nos permite utilizarla con un intervalo de tiempo para alarma que queramos: Por lo visto en widnows da error, solo se peude usar en unix o que hay que actualizar la versión de "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'signal' has no attribute 'alarm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-ec72f7bcf694>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-ec72f7bcf694>\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[1;31m# Set an alarm for 5 seconds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0msignal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malarm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_seconds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                 \u001b[1;31m# Call the decorated func\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'signal' has no attribute 'alarm'"
     ]
    }
   ],
   "source": [
    "import signal\n",
    "def timeout(n_seconds):\n",
    "    def decorator(func):    \n",
    "        @wraps(func)    \n",
    "        def wrapper(*args, **kwargs):\n",
    "            # Set an alarm for 5 seconds\n",
    "            signal.alarm(n_seconds)\n",
    "            try:\n",
    "                # Call the decorated func\n",
    "                return func(*args, **kwargs)\n",
    "            finally:\n",
    "                # Cancel alarm\n",
    "                signal.alarm(0)\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@timeout(20)\n",
    "def bar():\n",
    "    time.sleep(10)\n",
    "    print('bar!')\n",
    "    \n",
    "    \n",
    "bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tags\n",
    "\n",
    "Podemos poner etiqueas a funciones para por ejemplo:\n",
    "\n",
    "- Adding information about who has worked on the function, so a user can look up who to ask if they run into trouble using it.\n",
    "- Labeling functions as \"experimental\" so that users know that the inputs and outputs might change in the future.\n",
    "- Marking any functions that you plan to remove in a future version of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test', 'this is a tag')\n"
     ]
    }
   ],
   "source": [
    "def tag(*tags):\n",
    "    # Define a new decorator to return\n",
    "    def decorator(func):\n",
    "        # Ensure the decorated function keeps its metadata\n",
    "        @wraps(func)                                                                \n",
    "        def wrapper(*args, **kwargs):\n",
    "            # Call the function being decorated and return the result\n",
    "            return func(*args, **kwargs)\n",
    "        wrapper.tags = tags\n",
    "        return wrapper\n",
    "    # Return the new decorator\n",
    "    return decorator\n",
    "\n",
    "@tag('test', 'this is a tag')\n",
    "def foo():\n",
    "    pass\n",
    "\n",
    "print(foo.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Command Line Intermediate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables en la línea de comandos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````\n",
    "OS=linux\n",
    "OPERATING_SYSTEM=\"linux\"\n",
    "````\n",
    "\n",
    "Para palabras únicas da igual pone comillas o no, siempre con mayúsculas\n",
    "\n",
    "````\n",
    "ANIMAL=\"Shark with a laser beam on its head\"\n",
    "````\n",
    "\n",
    "No se puede poner espacios después del = como si estuvieras programando\n",
    "\n",
    "Para llamar a la variable ne la línea se pone echo y la variable $ delante.\n",
    "\n",
    "Si no lleva $ lo interpreta como la ejecución de un programa y da error si no existe ninguno que se llame así en el PATH.\n",
    "\n",
    "````\n",
    "FOOD=\"Shrimp gumbo\"\n",
    "echo $FOOD\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables de entorno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sirven para poder llamarlas desde cualquier programa que corramos en shell\n",
    "\n",
    "````\n",
    "export FOOD=\"Chicken and waffles\"\n",
    "\n",
    "````\n",
    "\n",
    "Podemos ejecutar python desde Bash con comando\n",
    "\n",
    "````\n",
    "python\n",
    "\n",
    "````\n",
    "\n",
    "y\n",
    "\n",
    "```` \n",
    "exit()\n",
    "\n",
    "```` \n",
    "\n",
    "para salir\n",
    "\n",
    "primero con python, que ya está en el PATH y luego dos comandos:\n",
    "\n",
    "````\n",
    "import os\n",
    "print(os.environ[\"FOOD\"])\n",
    "````\n",
    "\n",
    "- os incluye funciones para interactuar con el SO\n",
    "\n",
    "- os.environ es un diccionario con los valores de las variables de entorno, se puede acceder dando el key como una string. Ya habíamos añadido FOOD a las variables de entorno\n",
    "\n",
    "El programa python está instalado en\n",
    "\n",
    "````\n",
    "/usr/bin/python\n",
    "\n",
    "````\n",
    "\n",
    "Si hacemos\n",
    "\n",
    "\n",
    "````\n",
    "echo $PATH\n",
    "\n",
    "````\n",
    "\n",
    "veremos que esta ruta ya estaba en el PATH.\n",
    "\n",
    "\n",
    "Para añadir nuevas rutas a nuestro PATH (en este caso añadir /usr/bin)\n",
    "\n",
    "````\n",
    "export PATH=\"/usr/bin:$PATH\"\n",
    "\n",
    "````\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comandos y Flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos requieren argumentos, otros no.\n",
    "\n",
    "python no, cp sí, ls tiene opcionales\n",
    "\n",
    "````\n",
    "ls -al\n",
    "ls --all\n",
    "\n",
    "````\n",
    "\n",
    "Los dos de arriba son lo mismo, uno en largo y otro en corto\n",
    "\n",
    "````\n",
    "ls --ignore=test.txt\n",
    "ls -al --ignore=.ipython\n",
    "\n",
    "````\n",
    "\n",
    "Estos incluirían todos los archivos menos lo que ponga en ignore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Command Line Python Scripting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No es útil estar añadiendo comando de python líne a a línea\n",
    "\n",
    "\n",
    "````\n",
    "echo -e 'if __name__ == \"__main__\":\\n    print(\"Welcome to a Python script\")' > script.py\n",
    "python script.py\n",
    "\n",
    "````\n",
    "\n",
    "Crea un archivo .py y o ejecuta\n",
    "\n",
    "The code above will print Welcome to a Python script when we run it from the command line. To run it, we just need to put those lines into a file, save the file as file.py, and then call it with python file.py.\n",
    "\n",
    "This code works because the __name__ variable in Python scripts is automatically set to the name of the module. If the module is being run from the command line, the __name__ variable will be __main__ by default. Checking the __name__ variable allows us to tell whether a script is running from the command line or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to a Python script\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Welcome to a Python script\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages\n",
    "\n",
    "Son importantes para extender la funcionalidad de python. (Matplotlib, Pandas,..).\n",
    "\n",
    "La mejor manera de instalarlos es **pip**. Las versiones más nuevas de python incluyen pip por defecto.\n",
    "\n",
    "````\n",
    "pip install requests \n",
    "\n",
    "````\n",
    "\n",
    "Instala requests, que es un pkg para interaccionar con websites y APIs.\n",
    "\n",
    "Esto instalará requests en la versión de Python que esté por defecto en el comando python. Si queremos instalarlo en nuestro Python3, ¿cómo lo hacemos?\n",
    "Tendríamos que instalar los pkgs de manera global y  estar cambiando continuamente el ejecutable de python 2 por el 3 según el poryecto.\n",
    "\n",
    "Para facilitar las cosas aparecen los entornos virtuales\n",
    "\n",
    "#### Virtualenv\n",
    "\n",
    "Con virtualenv seguido de un nombre creamos un entorno virtual con una carpeta que contiene todos los pkgs que queramos instalar en él\n",
    "\n",
    "````\n",
    "virtualenv nombre\n",
    "\n",
    "virtualenv python2 \n",
    "\n",
    "````\n",
    "\n",
    "Es virtualenv también es un pkg a instalar\n",
    "\n",
    "Por defecto virtualenv usa el ejecutable python del sistema.\n",
    "\n",
    "Si queremos crear un venv con python3 tendremos que indicarlo con una flag -p en el comando. Esta flag permite cambiar el interpreter de python qie usa el venv.\n",
    "\n",
    "\n",
    "````\n",
    "virtualenv -p /usr/bin/python3 python3\n",
    "````\n",
    "\n",
    "Para activar el venv utilizamos el comando: \n",
    "\n",
    "````\n",
    "\n",
    "source python3/bin/activate\n",
    "\n",
    "````\n",
    " \n",
    " \n",
    "El activate está dentro de la carpeta bin creada en el venv.\n",
    "\n",
    "Una vez activado la versión de python y los pkgs instalados son los que correrán por defecto.\n",
    "\n",
    "Para desactivar el venv se usa el comando \n",
    "\n",
    "````\n",
    "deactivate\n",
    "\n",
    "````\n",
    "\n",
    "Para ver la versión de python del venv:\n",
    "\n",
    "\n",
    "````\n",
    "python -v\n",
    "\n",
    "````\n",
    "\n",
    "Para ver todos los paquetes de ese venv\n",
    "\n",
    "````\n",
    "pip freeze\n",
    "````\n",
    "\n",
    "El pip que aparece es el propio del venv en el que estamos.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importar funciones de pkgs\n",
    "\n",
    "Podemos importar funciones y clases de un archivo a otro con import.\n",
    "\n",
    "\n",
    "Por ejemplo creamos una función en utils.py\n",
    "\n",
    "````\n",
    "echo -e 'def print_message():\\n    print(\"Hello from another file!\")' > utils.py\n",
    "\n",
    "````\n",
    "\n",
    "Creamos un programa llamado script.py que importa el otro archivo\n",
    "\n",
    "````\n",
    "echo -e 'import utils\\n\\nif __name__ == \"__main__\":\\n    utils.print_message()' > script.py\n",
    "\n",
    "````\n",
    "\n",
    "Ejecutamos el  segundo\n",
    "\n",
    "````\n",
    "python script.py\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_message():\n",
    "    print(\"Hello from another file!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1ba65d5b4168>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    utils.print_message()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pasar opciones con línea de comandos a los scripts\n",
    "\n",
    "Con el pkg sys podemos ver los argumentos del comando con el script al que llamas.\n",
    "\n",
    "Los argumentos son posicionales en orden de escritura\n",
    "\n",
    "\n",
    "Modificamos el script.py para poder ver los comandos\n",
    "\n",
    "````\n",
    "echo -e 'import utils\\n\\nif __name__ == \"__main__\":\\n    print(sys.argv[1])' > script.py\n",
    "\n",
    "\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-f\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(sys.argv[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si llamamos a script.py con el comando:\n",
    "\n",
    "````\n",
    "python script.py \"Hello from the command line\"\n",
    "````\n",
    "\n",
    "El sys.argv[1] coge el segundo argumento, ya que el primero es el nombre del archivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notas del challenge\n",
    "\n",
    "Para ver directorio actual\n",
    "\n",
    "````\n",
    "pwd\n",
    "````\n",
    "\n",
    "Para cambiar permisos de lectura, escritura, ejecución\n",
    "\n",
    "````\n",
    "chmod u=rwx,g-r,o-r script.py\n",
    "\n",
    "````\n",
    "\n",
    "Pone rwx en usuario, quita r en grupos y others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working With Jupyter Console"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La Jupyter Console antes se conocía como IPython.\n",
    "\n",
    "Sirve para probar cosas rápidas en datasets. Para código medianamnete largo es más práctico el notebook.\n",
    "\n",
    "Para ejecutarlo se usa uno de los dos comandos:\n",
    "\n",
    "````\n",
    "jupyter console\n",
    "\n",
    "ipython\n",
    "\n",
    "````\n",
    "\n",
    "Se sale escribiendo exit o q\n",
    "\n",
    "\n",
    "Para ver la ayuda se puede escribir ? o help()\n",
    "\n",
    "variable? o help(variable) da información sobre esa variable.\n",
    "\n",
    "%quickref es una magic que muestra comandos útiles.\n",
    "\n",
    "Como en el notebook, esta consola inicia una sesión de kernel en el que se guardan todas las variables con las que vas trabajando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jupyter Magic\n",
    "\n",
    "%quickref muestra la magic disponible\n",
    "\n",
    "La lista completa [aquí](https://ipython.readthedocs.io/en/stable/interactive/magics.html)\n",
    "\n",
    "Algunos son:\n",
    "\n",
    "%run -- allows you to run an external Python script. Any variables in the script will be stored in the current kernel session.\n",
    "\n",
    "%edit -- opens a file editor. Any code you type into the editor will be executed by Jupyter when you exit the editor.\n",
    "\n",
    "%debug -- if there's an error in any of your code, running %debug afterwards will open an interactive debugger you can use to trace the error.\n",
    "\n",
    "%history -- shows you the last few commands you ran.\n",
    "\n",
    "%save -- saves the last few commands you ran to a file.\n",
    "\n",
    "%who -- print all the variables in the session.\n",
    "\n",
    "%reset -- resets the session, and removes all stored variables.\n",
    "\n",
    "podemos crear un script con nano y luego ejecuttarlo con %run y ver todas las variables con %who\n",
    "\n",
    "\n",
    "##### Para pegar código\n",
    "\n",
    "%cpaste abre un área especial donde puedes pegar texto sin importar espacios y saltos de línea.\n",
    "\n",
    "Para pegar ctrl+insert y luego ctrl+shift  (solo pegar, no incluye copiar)\n",
    "\n",
    "Para acabar se añade -- y se cierra el área de copia\n",
    "\n",
    "\n",
    "%paste coge directamente del clipboard, pero no funciona con sistemas remotos que no tienen acceso a nuestro sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecutar shell commands desde Jupyter console\n",
    "\n",
    "Solo tenemos que añadir ! antes del comando:\n",
    "\n",
    "````\n",
    "!mkdir carpeta\n",
    "\n",
    "!touch archivo\n",
    "\n",
    "!ls\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"ls\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El volumen de la unidad C es OS\n",
      " El número de serie del volumen es: DA0E-9765\n",
      "\n",
      " Directorio de C:\\Users\\adrig\\Google Drive\\Data Science\\DataQuest\\Advanced Topics in Data Science\n",
      "\n",
      "16/02/2022  12:31    <DIR>          .\n",
      "16/02/2022  12:31    <DIR>          ..\n",
      "14/02/2022  18:29    <DIR>          .ipynb_checkpoints\n",
      "16/02/2022  12:31            14.919 Advanced Topics in Data Science.ipynb\n",
      "16/02/2022  12:29            33.306 mission-68-working-with-jupyter-console-takeaways.pdf\n",
      "14/02/2022  13:45            35.509 mission-96-working-with-programs-takeaways.pdf\n",
      "15/02/2022  21:03            34.060 mission-97-command-line-python-scripting-takeaways.pdf\n",
      "               4 archivos        117.794 bytes\n",
      "               3 dirs  162.349.019.136 bytes libres\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piping and Redirecting Output\n",
    "\n",
    "#### Direccionar de comando a archivo\n",
    "\n",
    "Se redirige la salida de un comando a un archivo con >\n",
    "\n",
    "Para sobreescribir o crear >\n",
    "\n",
    "Para añadir al final del archivo >>\n",
    "\n",
    "````\n",
    "\n",
    "echo '99 bottles of beer on the wall...' > beer.txt\n",
    "echo 'Take one down, pass it around, 98 bottles of beer on the wall...' >> beer.txt\n",
    "\n",
    "````\n",
    "\n",
    "\n",
    "#### Direccionar de archivo a  comando\n",
    "\n",
    "Teniendo un txt con esto:\n",
    "\n",
    "99 bottles of beer on the wall...\n",
    "Take one down, pass it around, 98 bottles of beer on the wall...\n",
    "\n",
    "````\n",
    "sort < beer.txt\n",
    "\n",
    "````\n",
    "\n",
    "Ordena las líneas. Si ponemos la flag -r lo hace en orden inverso\n",
    "\n",
    "#### Buscar en el contenido de un archivo de texto\n",
    "\n",
    "Con el comando grep\n",
    "\n",
    "````\n",
    "grep \"pass\" beer.txt\n",
    "\n",
    "grep \"beer\" beer.txt coffee.txt\n",
    "\n",
    "\n",
    "echo 'Coffee is almost as good as beer,\\nBut I could never drink 99 bottles of it' > coffee.txt\n",
    "grep \"bottles of\" beer.txt coffee.txt\n",
    "\n",
    "````\n",
    "\n",
    "#### Buscar en muchos archivos a la vez\n",
    "\n",
    "\n",
    "````\n",
    "beer.txt\n",
    "beer1.txt\n",
    "beer2.txt\n",
    "coffee.txt\n",
    "better_coffee.txt\n",
    "````\n",
    "Por ejemplo si tenemos muchos archivos que se llaman parecido podemos usar wildcards como ?\n",
    "\n",
    "````\n",
    "touch beer1.txt\n",
    "touch beer2.txt\n",
    "grep \"beer\" beer?.txt\n",
    "````\n",
    "\n",
    "````\n",
    "grep \"beer\" beer*.txt\n",
    "grep \"beer\" *.txt\n",
    "ls *.txt\n",
    "\n",
    "````\n",
    "\n",
    "#### Direccionar salida de comando a entrada de otro comando\n",
    "\n",
    "Se usa el pipe character |\n",
    "\n",
    "Por ejemplo esto busca en las 10 útilmas líneas de texto en logs.txt la palabra Error\n",
    "\n",
    "````\n",
    "tail -n 10 logs.txt | grep \"Error\"\n",
    "\n",
    "````\n",
    "\n",
    "Si tenemos un programa en python en rand.py tal que:\n",
    "\n",
    "````\n",
    "import random\n",
    "for i in range(10000):\n",
    "    print(random.randint(1,10))\n",
    "\n",
    "````\n",
    "\n",
    "El comando\n",
    "````\n",
    "python rand.py | grep 9\n",
    "\n",
    "````\n",
    "\n",
    "Sacaría 9 (porque es lo que está buscando) cuando el output del programa sea 9.\n",
    "\n",
    "\n",
    "#### Ejecutar comandos secuencialmente\n",
    "\n",
    "Se hace con &&.\n",
    "\n",
    "Si el primero no da error, se ejcuta el siguiente.\n",
    "\n",
    "````\n",
    "echo \"All the beers are gone\" >> beer.txt && cat beer.txt\n",
    "\n",
    "````\n",
    "\n",
    "\n",
    "El comando cat concatena los contenidos de un archivo y los muestra.\n",
    "\n",
    "\n",
    "#### Caracteres especiales de Bash\n",
    "\n",
    "[Aquí](https://tldp.org/LDP/abs/html/special-chars.html) una lista.\n",
    "\n",
    "Si queremos añadir uno de estos caracteres en un texto sin que haga nada hay que utilizar el escape character \\\n",
    "\n",
    "````\n",
    "echo \"\\\"Get out of here,\\\" said Neil Armstrong to the moon people.\" >> famous_quotes.txt\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Munging con Command Line\n",
    "\n",
    "Consiste en transformar datasets para hacerlos más manejables. Algunos son demasiado grandes para cargar en Python y hay que transformarlos antes.\n",
    "\n",
    "Para más pequeños también merece la pena explorarlos y unificarlos en la línea de comandos.\n",
    "\n",
    "\n",
    "Por ejemplo si tenemos estos 3 csv de datasets on U.S. housing affordability from the U.S. Department of Housing & Urban Development.\n",
    "\n",
    "````\n",
    "/home/dq$ ls -al\n",
    "total 6740\n",
    "drwxr-xr-x 1 dq   dq      4096 Feb 16 19:24 .\n",
    "drwxr-xr-x 1 root root    4096 Nov 18  2020 ..\n",
    "-rw-r--r-- 1 dq   dq      4496 Feb 16 19:24 .bashrc\n",
    "drwxr-xr-x 1 dq   dq      4096 Nov 18  2020 .byobu\n",
    "drwxr-xr-x 1 dq   dq      4096 Nov 18  2020 .cache\n",
    "drwxr-xr-x 1 dq   dq      4096 Nov 18  2020 .config\n",
    "-rw-r--r-- 1 dq   dq        25 Nov 18  2020 .gitconfig\n",
    "-rwxr-xr-x 1 dq   dq   2051577 Feb 16 19:24 Hud_2005.csv\n",
    "-rwxr-xr-x 1 dq   dq   1874334 Feb 16 19:24 Hud_2007.csv\n",
    "-rwxr-xr-x 1 dq   dq   2902856 Feb 16 19:24 Hud_2013.csv\n",
    "drwxr-xr-x 1 dq   dq      4096 Feb 16 19:24 .ipython\n",
    "drwxr-xr-x 2 dq   dq      4096 Nov 18  2020 .jupyter\n",
    "drwx------ 3 dq   dq      4096 Nov 18  2020 .local\n",
    "-rw-r--r-- 1 dq   dq        17 Nov 18  2020 .tmux.conf\n",
    "\n",
    "````\n",
    "\n",
    "\n",
    "Podemos usar el comando head para mostrar sus primeras líneas (10 por defecto):\n",
    "\n",
    "````\n",
    "head -n 10 *.csv\n",
    "\n",
    "````\n",
    "\n",
    "Y la salida es\n",
    "\n",
    "\n",
    "````\n",
    "==> Hud_2005.csv <==\n",
    "AGE1,BURDEN,FMR,FMTBEDRMS,FMTBUILT,TOTSAL\n",
    "43,0.513,680,'3 3BR','1980-1989',20000\n",
    "44,0.2225915493,760,'4 4BR+','1980-1989',71000\n",
    "58,0.2178312657,680,'3 3BR','1980-1989',63000\n",
    "22,0.21745562129999998,519,'1 1BR','1980-1989',27040\n",
    "48,0.28285714289999997,600,'1 1BR','1980-1989',14000\n",
    "42,0.2922857143,788,'3 3BR','1980-1989',42000\n",
    "-9,-9.0,702,'2 2BR','1980-1989',-9\n",
    "23,0.14475,546,'2 2BR','1980-1989',48000\n",
    "51,0.2962,680,'3 3BR','1980-1989',58000\n",
    "\n",
    "==> Hud_2007.csv <==\n",
    "AGE1,BURDEN,FMR,FMTBEDRMS,FMTBUILT,TOTSAL\n",
    "-9,-9.0,1048,'3 3BR','2000-2009',-9\n",
    "69,0.1207594937,1048,'3 3BR','2000-2009',0\n",
    "45,0.3683076923,757,'3 3BR','1980-1989',26000\n",
    "47,0.099419707,847,'4 4BR+','1980-1989',126000\n",
    "30,0.1340625,616,'2 2BR','1980-1989',42000\n",
    "50,0.2824,605,'1 1BR','1980-1989',15000\n",
    "44,0.0885517241,807,'3 3BR','1980-1989',145000\n",
    "-9,-9.0,778,'2 2BR','1980-1989',-9\n",
    "24,0.07925,599,'2 2BR','1980-1989',96000\n",
    "\n",
    "==> Hud_2013.csv <==\n",
    "AGE1,BURDEN,FMR,FMTBEDRMS,FMTBUILT,TOTSAL\n",
    "82,0.35491926090000003,956,'2 2BR','2000-2009',0\n",
    "50,0.047527264699999995,1100,'4 4BR+','1980-1989',123000\n",
    "53,0.6027025095,1100,'4 4BR+','1980-1989',28000\n",
    "67,0.1039106145,949,'3 3BR','1980-1989',0\n",
    "26,0.094019035,737,'2 2BR','1980-1989',96900\n",
    "56,0.5564822846,657,'1 1BR','1980-1989',15000\n",
    "50,0.1998227609,988,'3 3BR','1980-1989',70001\n",
    "26,0.366,773,'2 2BR','1980-1989',20000\n",
    "60,0.1165841647,1125,'3 3BR','1980-1989',107000\n",
    "\n",
    "````\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Combinando DataFrames\n",
    "\n",
    "Creamos un archivo nuevo combined_hud.csv con un header como cualquiera de los 3 datasets que tenemos.\n",
    "\n",
    "Seleccionamos todo lo que no sea header de uno y lo añadimos al nuevo archivo.\n",
    "\n",
    "Para conocer el número de líneas de un dataset; wc con flag l \n",
    "\n",
    "````\n",
    "head -1 Hud_2005.csv > combined_hud.csv\n",
    "wc -l Hud_2005.csv\n",
    "tail -46853 Hud_2005.csv >> combined_hud.csv\n",
    "head combined_hud.csv\n",
    "````\n",
    "\n",
    "Añadimos los otros dos igual en orden temporal:\n",
    "\n",
    "````\n",
    "wc -l Hud_2007.csv\n",
    "tail -42729 Hud_2007.csv >> combined_hud.csv\n",
    "wc -l Hud_2013.csv\n",
    "tail -64535 Hud_2013.csv >> combined_hud.csv\n",
    "````\n",
    "\n",
    "Ahora por ejemplo podemos contar el número de líneas del conjunto que contienen \"1980-1989\" con:\n",
    "\n",
    "````\n",
    "grep \"1980-1989\" combined_hud.csv | wc -l \n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Exploration Using Csvkit\n",
    "\n",
    "Hasta ahora hemos hecho data munging de manera poco efieciente con comandos que realmente no son muy potentes para manejar data sets en csv.\n",
    "\n",
    "Una herramienta pensada para hacer esto fácilemte es csvkit.\n",
    "\n",
    "Las instrucciones para instalarlo son [estas](https://csvkit.readthedocs.io/en/0.9.1/install.html).\n",
    "\n",
    "Algunos de los comandos son estos:\n",
    "\n",
    "- csvstack: for stacking rows from multiple CSV files.\n",
    "- csvlook: renders CSV in pretty table format.\n",
    "- csvcut: for selecting specific columns from a CSV file.\n",
    "- csvstat: for calculating descriptive statistics for some or all columns.\n",
    "- csvgrep: for filtering tabular data using specific criteria.\n",
    "\n",
    "\n",
    "\n",
    "#### Csvstack\n",
    "\n",
    "Si queremos apilar varios datasets con el mismo header.\n",
    "\n",
    "````\n",
    "csvstack file1.csv file2.csv file3.csv > final.csv\n",
    "````\n",
    "\n",
    "Hay que redireccionar el stdout a un archivo o aun head, si no la salida será todo el dataset unido y puede bloquear la terminal.\n",
    "\n",
    "Se puede dejar una traza de dónde viene cada row con la flag -g, de qué archivo viene esa row. Se añadirá el valor correspondiente a una nueva columna.\n",
    "\n",
    "Con la flag -n se puede nombrar a esa nueva columna\n",
    "\n",
    "````\n",
    "csvstack -n origin -g 1,2,3 file1.csv file2.csv file3.csv > final.csv\n",
    "\n",
    "````\n",
    "\n",
    "Aquí se ponen valores en a nueva columna year que corresponden a cada año\n",
    "\n",
    "````\n",
    "\n",
    "csvstack -n year -g 2005,2007,2013 Hud_2005.csv Hud_2007.csv Hud_2013.csv > Combined_hud.csv\n",
    "head -5 Combined_hud.csv\n",
    "\n",
    "````\n",
    "\n",
    "#### Csvlook\n",
    "\n",
    "Sirve para darle un formato de tabla a una salida tipo head.\n",
    "\n",
    "````\n",
    "head -10 Combined_hud.csv | csvlook\n",
    "````\n",
    "\n",
    "#### Csvcut\n",
    "\n",
    "Sirve para estudar columnas por separado.\n",
    "\n",
    "Con la flag -n muestra las columnas:\n",
    "\n",
    "````\n",
    "csvcut -n Combined_hud.csv\n",
    "\n",
    "````\n",
    "\n",
    "La salida es:\n",
    "\n",
    "\n",
    "````\n",
    "1: year\n",
    "2: AGE1\n",
    "3: BURDEN\n",
    "4: FMR\n",
    "5: FMTBEDRMS\n",
    "6: FMTBUILT\n",
    "7: TOTSAL\n",
    "\n",
    "\n",
    "````\n",
    "\n",
    "\n",
    "Para seleccionar una de las columnas se usa la flag -c con el número de columna.\n",
    "\n",
    "Es mejor pasarlo por pipe a un head para no mostrar todas las rows porque un dataset grande puede bloquear la terminal:\n",
    "\n",
    "\n",
    "````\n",
    "csvcut -c 1 Combined_hud.csv | head -10\n",
    "\n",
    "````\n",
    "\n",
    "#### Cvstat\n",
    "\n",
    "Calcula summary statistics de las columnas.\n",
    "\n",
    "- max,\n",
    "- min,\n",
    "- sum,\n",
    "- mean,\n",
    "- median,\n",
    "- standard deviation.\n",
    "\n",
    "\n",
    "De una sola columna todos los summary statistics:\n",
    "\n",
    "````\n",
    "csvcut -c 4 Combined_hud.csv | csvstat\n",
    "\n",
    "````\n",
    "Algunos específicos:\n",
    "````\n",
    "# Just the max value.\n",
    "csvcut -c 2 Combined_hud.csv | csvstat --max\n",
    "# Just the mean value.\n",
    "csvcut -c 2 Combined_hud.csv | csvstat --mean\n",
    "# Just the number of null values.\n",
    "csvcut -c 2 Combined_hud.csv | csvstat --nulls\n",
    "````\n",
    "\n",
    "Todos de todas las columnas:\n",
    "\n",
    "````\n",
    "\n",
    "csvstat Combined_hud.csv\n",
    "\n",
    "````\n",
    "\n",
    "Solo la media de todas:\n",
    "````\n",
    "csvstat --mean Combined_hud.csv \n",
    "````\n",
    "\n",
    "La salida sería:\n",
    "\n",
    "````\n",
    "1. year: 2008.9044232628457\n",
    "2. AGE1: 46.511215505103266\n",
    "3. BURDEN: 5.303764743668771\n",
    "4. FMR: 1037.1186695822005\n",
    "5. FMTBEDRMS: None\n",
    "6. FMTBUILT: None\n",
    "7. TOTSAL: 44041.841931779105\n",
    "\n",
    "````\n",
    "\n",
    "Si buscamos problemas en la columna AGE1 (2):\n",
    "\n",
    "````\n",
    "csvcut -n Combined_hud.csv\n",
    "csvcut -c 2 Combined_hud.csv | csvstat\n",
    "\n",
    "````\n",
    "\n",
    "Vemos la salida:\n",
    "\n",
    "````\n",
    "1. AGE1\n",
    "        <class 'int'>\n",
    "        Nulls: False\n",
    "        Min: -9\n",
    "        Max: 93\n",
    "        Sum: 7168169\n",
    "        Mean: 46.511215505103266\n",
    "        Median: 48\n",
    "        Standard Deviation: 23.04901451351246\n",
    "        Unique values: 80\n",
    "        5 most frequent values:\n",
    "                -9:     11553\n",
    "                50:     3208\n",
    "                45:     3056\n",
    "                40:     3040\n",
    "                48:     3006\n",
    "\n",
    "Row count: 154117\n",
    "\n",
    "````\n",
    "\n",
    "Vemos que el valor mínimo es -9 en la edad, lo que es un error.\n",
    "\n",
    "Podemos investigar más buscando qué líneas tienen este valor. Para ello tenemos un comando similar a grep\n",
    "\n",
    "#### Csvgrep\n",
    "\n",
    "Sirve para buscar row que contengan un patrón específico.\n",
    "\n",
    "Si queremos buscar las rows que tewngan un valor en en una columna determinada usamos la flag -m:\n",
    "\n",
    "````\n",
    "csvgrep -c 2 -m -9 Combined_hud.csv\n",
    "\n",
    "````\n",
    "\n",
    "Si queremos buscar según una regular expression usamos la flag -r\n",
    "\n",
    "\n",
    "Los 10 valores primeros de la columna 2 que tienen valor -9 en una tabla:\n",
    "\n",
    "````\n",
    "csvgrep -c 2 -m -9 Combined_hud.csv | head -10 | csvlook\n",
    "\n",
    "````\n",
    "\n",
    "\n",
    "Y la salida:\n",
    "\n",
    "````\n",
    "|-------+------+--------+------+-----------+-------------+---------|\n",
    "|  year | AGE1 | BURDEN | FMR  | FMTBEDRMS | FMTBUILT    | TOTSAL  |\n",
    "|-------+------+--------+------+-----------+-------------+---------|\n",
    "|  2005 | -9   | -9.000 | 702  | '2 2BR'   | '1980-1989' | -9      |\n",
    "|  2005 | -9   | -9.000 | 531  | '1 1BR'   | '1980-1989' | -9      |\n",
    "|  2005 | -9   | -9.000 | 1034 | '3 3BR'   | '2000-2009' | -9      |\n",
    "|  2005 | -9   | -9.000 | 631  | '1 1BR'   | '1980-1989' | -9      |\n",
    "|  2005 | -9   | -9.000 | 712  | '4 4BR+'  | '1990-1999' | -9      |\n",
    "|  2005 | -9   | -9.000 | 1006 | '3 3BR'   | '2000-2009' | -9      |\n",
    "|  2005 | -9   | -9.000 | 631  | '1 1BR'   | '1980-1989' | -9      |\n",
    "|  2005 | -9   | -9.000 | 712  | '3 3BR'   | '2000-2009' | -9      |\n",
    "|  2005 | -9   | -9.000 | 1087 | '3 3BR'   | '2000-2009' | -9      |\n",
    "|-------+------+--------+------+-----------+-------------+---------|\n",
    "\n",
    "\n",
    "````\n",
    "\n",
    "Hay que quitatr estas filas problemáticas, pero Csvkit no se desarrolló para editar archivos. Lo más sencillo es crear un archivo separado con las filas que nos interesan.\n",
    "\n",
    "Se puede usar csvgrep para seleccionar las rows que no coincidan con el patrón mediante la flag -i\n",
    "\n",
    "````\n",
    "csvgrep -c 2 -m -9 -i Combined_hud.csv > positive_ages_only.csv\n",
    "\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liminatciones de Csvkit\n",
    "\n",
    "- Csvkit is not optimized for speed and struggles to run some commands over larger files.\n",
    "\n",
    "- Csvkit has very limited capabilities for actually editing problematic values in a dataset, since the community behind the library aspired to keep the library small and lightweight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Git and Version Control\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay otros controladores de versión como Mercurial o Bazaar pero Git es el más popular con diferencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creamos una carpeta y la inicializamos como repositorio de Git\n",
    "\n",
    "````\n",
    "mkdir random_numbers\n",
    "git init random_numbers\n",
    "\n",
    "\n",
    "````\n",
    "\n",
    "Se crea una carpeta oculta dentro de random_numbers que será .git\n",
    "\n",
    "El workflow de Git implica añadir archivos , hacer cambios, hacer un snapshot de esos cambios (commit)\n",
    "\n",
    "Git guarda la diferencia (diff) de lo que cambia entre commits.\n",
    "\n",
    "Todo proyecto es una secuencia de commits.\n",
    "\n",
    "Así puede fusionar los cambios de mucha gente a la vez y restaurar a un punto anterior.\n",
    "\n",
    "Como ejemplo genaramos dos ficheros:\n",
    "\n",
    "````\n",
    "echo -e \"Random number generator\" > README.md\n",
    "echo -e 'if __name__ == \"__main__\":\\n    print(\"10\")' > script.py\n",
    "````\n",
    "\n",
    "Los archivos pueden tener tres estados en Git:\n",
    "\n",
    "- commited : La versión actual se ha añadido a un commit y Git lo tiene guardado.\n",
    "\n",
    "- staged : El archivo está marcado para incluir en el siguiente commit. Se puede trabajar en otro archivo y luego hacer commit de los dos a la vez, pej.\n",
    "\n",
    "- modified : El archivo está modificado respecto al último commit pero no está staged.\n",
    "\n",
    "Para ver el estado de los archivos del repo se ejecuta:\n",
    "\n",
    "````\n",
    "git status\n",
    "\n",
    "````\n",
    "\n",
    "Lo que no aparezca en git status está en estado commited.\n",
    "\n",
    "Para añadir al área de staging se hace con \n",
    "\n",
    "````\n",
    "git add script.py\n",
    "````\n",
    "\n",
    "#### Configuración\n",
    "\n",
    "Antes de hacer commits hay que configurar para identificar al usuario que hace los cambios.\n",
    "\n",
    "````\n",
    "\n",
    "git config --global user.email \"your.email@domain.com\"\n",
    "git config --global user.name \"Your name\"\n",
    "\n",
    "````\n",
    "\n",
    "\n",
    "Hacemos el commit poniendo un mensaje informativo con la flag -m:\n",
    "\n",
    "````\n",
    "git commit -m \"Initial commit. Added script.py and README.md\"\n",
    "````\n",
    "\n",
    "\n",
    "Si modificamos ahora los archivos\n",
    "\n",
    "````\n",
    "echo -e 'import random\\nif __name__ == \"__main__\":\\n    print(random.randint(0,10))' > script.py\n",
    "\n",
    "\n",
    "````\n",
    "\n",
    "Podemos ver la diferencia con lo anterior con \n",
    "\n",
    "````\n",
    "git diff\n",
    "\n",
    "````\n",
    " Para lo que esté ya staged\n",
    " \n",
    "\n",
    "````\n",
    "git diff --staged\n",
    "\n",
    "```` \n",
    " \n",
    "Cuando la salida es grande se puede hacer scroll con las flechas y slir con q.\n",
    "\n",
    "\n",
    "#### Commit history\n",
    "\n",
    "Para ver el log de commits:\n",
    "\n",
    "````\n",
    "\n",
    "git log\n",
    "\n",
    "````\n",
    "\n",
    "Para ver más información:\n",
    "\n",
    "\n",
    "````\n",
    "\n",
    "git log --stat\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Git Remotes\n",
    "\n",
    "Es útil utilizar Git junto con GitHub, que permite hacer push de tu código a repositorios remotos.\n",
    "\n",
    "Para descargar/clonar un repositorio remoto necesitamos la URL del mismo\n",
    "\n",
    "````\n",
    "git clone https://github.com/amznlabs/amazon-dsstne.git\n",
    "\n",
    "````\n",
    "\n",
    "Si quisieramos copiar de un repo local a otra carpeta local\n",
    "\n",
    "````\n",
    "git clone /dataquest/user/git/chatbot chatbot\n",
    "````\n",
    "\n",
    "\n",
    "Va de la carpeta chatbot  en /dataquest... a la carpeta chatbot en el directorio actual.\n",
    "\n",
    "Las modificaciones de un repo clonado solo se aplican al nuevo.\n",
    "\n",
    "![title](imagenes/local_remote_repo.png)\n",
    "\n",
    "Si ahora modificamos el readme y ejecutamos un git status:\n",
    "\n",
    "````\n",
    "On branch master                                                                \n",
    "Your branch is ahead of 'origin/master' by 1 commit.                            \n",
    "  (use \"git push\" to publish your local commits)\n",
    "\n",
    "nothing to commit, working directory clean\n",
    "\n",
    "````\n",
    "\n",
    "Los repos consisten en una o más branches. La principal se llama típicamente master.\n",
    "\n",
    "Otras ramas deberían acabar añadiéndose al master.\n",
    "\n",
    "Comprobamos la branch actual con:\n",
    "\n",
    "````\n",
    "git branch\n",
    "````\n",
    "\n",
    "Cuando queramos guardar los cambios locales en el repo remoto se utiliza push\n",
    "\n",
    "````\n",
    "git push origin master\n",
    "````\n",
    "\n",
    "Cuando clonamos un repo Git nombra al remote como **origin**\n",
    "\n",
    "Para ver la lista de los remotes asociados al repo local usamos\n",
    "````\n",
    "git remote -v\n",
    "\n",
    "````\n",
    "\n",
    "Con -v incluye info de donde están los repos ubicados\n",
    "\n",
    "![title](imagenes/push_repo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La historia de un repo es una serie de commits.\n",
    "\n",
    "Cada commit contiene lo que cambia respecto al anterior commit.\n",
    "\n",
    "Es una forma muy eficiente de guardar la historia y permite reconstruir el directorio de trabajo.\n",
    "\n",
    "Los commits están separados del directorio de trabajo, son imágenes del directorio en diferentes tiempos.\n",
    "\n",
    "Para ver la historia completa\n",
    "\n",
    "````\n",
    "\n",
    "git log\n",
    "````\n",
    "\n",
    "Que tendrá una salida tal que\n",
    "\n",
    "````\n",
    "commit 6a95e94ea10caa28013b767510d4bc59369d83fa                                 \n",
    "Author: Dataquest <me@dataquest.io>                                             \n",
    "Date:   Wed May 18 21:56:27 2016 +0000                                          \n",
    "\n",
    "    Updated README.md                                                           \n",
    "\n",
    "commit 8a1ca35dd5c5de8f93aa6cbbd153caa40233386c                                 \n",
    "Author: Dataquest <me@dataquest.io>                                             \n",
    "Date:   Wed May 18 21:55:33 2016 +0000                                          \n",
    "\n",
    "    Add the initial version of README.md\n",
    "\n",
    "````\n",
    "\n",
    "Para ver con más detalle cada commit se copia el hash code corrspodniente y se ejecuta git show \n",
    "\n",
    "````\n",
    "\n",
    "git show 6a95e94ea10caa28013b767510d4bc59369d83fa\n",
    "\n",
    "````\n",
    "\n",
    "\n",
    "La salida será: (se puede hacer scroll y se sale con q)\n",
    "\n",
    "\n",
    "````\n",
    "commit 6a95e94ea10caa28013b767510d4bc59369d83fa                                 \n",
    "Author: Dataquest <me@dataquest.io>                                             \n",
    "Date:   Wed May 18 21:56:27 2016 +0000                                          \n",
    "\n",
    "    Updated README.md                                                           \n",
    "\n",
    "diff --git a/README.md b/README.md                                              \n",
    "index f4871de..9c05964 100644                                                   \n",
    "--- a/README.md                                                                 \n",
    "+++ b/README.md                                                                 \n",
    "@@ -1,3 +1,3 @@                                                                 \n",
    " README\n",
    "\n",
    "-This is a README file.  It's typical for GitHub projects to have a README.  A README gives information about what the project is about, and usually how to install and use it.\n",
    "\\ No newline at end of file                                                     \n",
    "+This is a README file.  It's typical for GitHub projects to have a README.  A README gives information about what the project is about, and usually how to install and use it.This project needs no installation!\n",
    "\n",
    "````\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interaction with commits\n",
    "\n",
    "Tenemos cambios en el working directory\n",
    "\n",
    "![title](imagenes/commit_workflow_1.png)\n",
    "\n",
    "Añadimos a fase stage\n",
    "````\n",
    "git add\n",
    "````\n",
    "\n",
    "![title](imagenes/commit_workflow_2.png)\n",
    "\n",
    "Añadimos a fase commit\n",
    "````\n",
    "git commit\n",
    "````\n",
    "\n",
    "Ahora tendremos un commit con un hash 53d asociado para identificarlo\n",
    "\n",
    "![title](imagenes/commit_workflow_3.png)\n",
    "\n",
    "Si ahora modificamos el wd con un nuevo archivo y repetimos tendremos otro commit con otro hash\n",
    "\n",
    "![title](imagenes/commit_workflow_4.png)\n",
    "![title](imagenes/commit_workflow_5.png)\n",
    "![title](imagenes/commit_workflow_6.png)\n",
    "\n",
    "\n",
    "Para ver la diferencia entre commits\n",
    "````\n",
    "git diff\n",
    "````\n",
    "\n",
    "Se puede poner como argumento los hash, con los 4 primeros caracteres suele bastar\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reset de commit / repositorio\n",
    "\n",
    "Los hashes de los commits son permanentes. Se conserva entre transferencias entre local y remoto.\n",
    "\n",
    "Podemos revertir cambios en el repo local fijándomos en los commits sin cambiar nada de cómo son los commits en el repo remoto. Estos e hace con git reset\n",
    "\n",
    "````\n",
    "git reset --hard c12\n",
    "\n",
    "git reset --sof c12\n",
    "````\n",
    "\n",
    "![title](imagenes/reset.png)\n",
    "\n",
    "The --hard flag resets both the working directory and the Git history to a specific state. If we omitted the flag, or used the --soft flag instead, it would skip making changes to the working directory, and only reset the Git history."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actualizar un repositorio local\n",
    "\n",
    "Es frecuente que cuando otras personas hagan cambios en un proyecto, el repo remoto tenga commits más nuevos que nuestro local.\n",
    "\n",
    "En el ejemplo, el repo remoto tiene un commit más reciente que el local.\n",
    "\n",
    "Para actualizar nuestro wd local haremos:\n",
    "\n",
    "````\n",
    "git pull origin master\n",
    "````\n",
    "\n",
    "![title](imagenes/pull.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shortcuts\n",
    "\n",
    "Va ser frecuente hacer referencia al commit más reciente para revertir cambios.\n",
    "\n",
    "Para ello la variable HEAD es muy útil. Hace referencia al hash del último último commit.\n",
    "\n",
    "HEAD\\~1 hace referencia a la siguiente y HEAD\\~2 a la siguiente y así sucesivamente.\n",
    "\n",
    "\n",
    "\n",
    "Esto resetea al segundo commit más reciente:\n",
    "\n",
    "````\n",
    "git reset --hard HEAD~1\n",
    "````\n",
    "\n",
    "\n",
    "Para ver el hash correspondiente a una de ellas se puede usar el comando\n",
    "\n",
    "````\n",
    "git rev-parse HEAD\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Git Branches\n",
    "\n",
    "Si todo el mundo trabaja en master y trata de hacer push a master se crearía merge conflicts, algo muy tedioso de solucionar.\n",
    "\n",
    "Aquí Supermán, Rocky y Sally han hecho un clone de remote con hash f34.\n",
    "\n",
    "Superman ha hecho un push en master y Rocky y Sally tienen commits que ya están en conflicto.\n",
    "\n",
    "![title](imagenes/merge_conflict.png)\n",
    "\n",
    "\n",
    "Aquí han hecho cada uno una branch\n",
    "\n",
    "![title](imagenes/branches.png)\n",
    "\n",
    "Cuando cada uno vaya haciendo push, se irán añadiendo sus branches y sus cambios. Cuando quieran hacer merge se podrá hacer de manera separada y sin conflictos.\n",
    "\n",
    "Para crear una branch\n",
    "\n",
    "````\n",
    "git branch more-speech\n",
    "````\n",
    "\n",
    "Para cambiar de branch\n",
    "\n",
    "````\n",
    "git scheckout more-speech\n",
    "````\n",
    "\n",
    "Se puede crear y cambiar con un atajo gracias a la flag -b:\n",
    "\n",
    "````\n",
    "git checkout -b more-speech\n",
    "````\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando modificamos una branch es igual que con la master. Hacemos add y commit.\n",
    "\n",
    "Los problemas surgen cuando cambiamos de ramas.\n",
    "\n",
    "Cambiar de rama altera el working directory para que refleje el último commit de esa rama.\n",
    "\n",
    "switch branch -> commit -> switch a master lo que hace es poner el wd en el estado del último commit del master.\n",
    "\n",
    "\n",
    "![title](imagenes/switch.png)\n",
    "\n",
    "\n",
    "Si tenemos en master un código print(1), cambiamos de branch, ponemos un código print(2) y volvemos a master tendremos print(1).\n",
    "\n",
    "Nota: se puede utilizar la función de C printf para escribir en archivos\n",
    "````\n",
    "printf \"print('2')\" >> bot.py\n",
    "\n",
    "````\n",
    "\n",
    "Hacemos push\n",
    "````\n",
    "git push origin more-speech\n",
    "\n",
    "````\n",
    "\n",
    "\n",
    "Ahora vemos las branches en el remoto (remoto flag -r, local flag -a):\n",
    "\n",
    "````\n",
    "git branch -r\n",
    "````\n",
    "\n",
    "Con salida:\n",
    "\n",
    "\n",
    "````\n",
    "origin/HEAD -> origin/master                                                  \n",
    "origin/master                                                                 \n",
    "origin/more-speech\n",
    "````\n",
    "\n",
    "Que dice que hay dos branches en el remote origin y que la branch actual (HEAD) es master. HEAD es current branch y lastest commit.\n",
    "\n",
    "\n",
    "#### Merge\n",
    "\n",
    "Todas las branches en algún momento tienen que fusionarse con la master. Merge nos permite copiar los commits de una branch en otra.\n",
    "\n",
    "````\n",
    "git checkout master\n",
    "git merge more-speech\n",
    "git push origin master\n",
    "````\n",
    "\n",
    "![title](imagenes/merge.png)\n",
    "\n",
    "\n",
    "#### Eliminar branch\n",
    "\n",
    "una vez se ha hecho merge y no existen diferencias entre el commit del master y de la branch es recomendable eliminar esa branch\n",
    "\n",
    "````\n",
    "git branch -d more-speech\n",
    "\n",
    "````\n",
    "\n",
    "Si una branch tiene cambios sin merge y aún así quieres eliminarlo\n",
    "\n",
    "````\n",
    "git branch -D more-speech\n",
    "\n",
    "````\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Branches de Colaboradores\n",
    "\n",
    "Para ver las branches de otra gente en el repo remoto creamos branches locales con el mismo nombre y los commits de las branchs remotas a las locales.\n",
    "\n",
    "Esto se hace de dos maneras distintas:\n",
    "\n",
    "- git fetch - Copia todas las branches del remote sin cambiarte el wd.\n",
    "\n",
    "- git checkout nombreBranch - Busca esa branch en el local y en el remoto. Si solo existe enr emoto lo copia en local y cambia a esa branch.\n",
    "\n",
    "\n",
    "Simulamos un colaborador en nuestro sistema con su propia carpeta de proyecto chatbot2 en cualquier otro sitio:\n",
    "\n",
    "````\n",
    "cd /home/dq\n",
    "git clone /dataquest/user/git/chatbot chatbot2\n",
    "cd chatbot2\n",
    "git checkout -b happy-bot\n",
    "printf \"\\nprint('Happiness level: 120')\" >> bot.py\n",
    "git add bot.py\n",
    "git commit -m \"Made the bot 20% happier!\"\n",
    "git push origin happy-bot\n",
    "\n",
    "\n",
    "````\n",
    "\n",
    "Comprobamos desde nuestra carpeta de proyecto chatbot\n",
    "\n",
    "````\n",
    "cd /home/dq\n",
    "cd chatbot\n",
    "git fetch\n",
    "git checkout happy-bot\n",
    "python bot.py\n",
    "````\n",
    "\n",
    "#### Flujo de trabajo típico de Git\n",
    "\n",
    "- Crear branch nueva desde master con el nombre de la nueva propiedad/feature\n",
    "\n",
    "- Hacer cambios en la nueva branch y crear commits\n",
    "\n",
    "- Push la branch nueva al remote\n",
    "\n",
    "- Pedir la verificación de otros miembros del equipo\n",
    "\n",
    "- Merge la branch en el master cuando esté verificado\n",
    "\n",
    "- Eliminar branch\n",
    "\n",
    "Es muy importante poder ver las diferencias entre la branch y el master \"the diff\".\n",
    "\n",
    "Con GitHub, las pull requests se muestran de manera visual y atractiva.\n",
    "\n",
    "Si no usamos GitHub podemos usar git diff con los nombres de las branches.\n",
    "\n",
    "Muestra línea a línea las adiciones + y las eliminaciones -.\n",
    "\n",
    "Es importante el orden de los argumentos en el comando.\n",
    "\n",
    "````\n",
    "\n",
    "cd /home/dq/chatbot\n",
    "git --no-pager diff master happy-bot\n",
    "````\n",
    "\n",
    "El no pager es opcional para que abra el pager o no.\n",
    "\n",
    "\n",
    "La salida sería:\n",
    "\n",
    "````\n",
    "diff --git a/bot.py b/bot.py\n",
    "index 9e0f4e3..265f8b2 100755\n",
    "--- a/bot.py\n",
    "+++ b/bot.py\n",
    "@@ -1,2 +1,2 @@\n",
    " if __name__ == \"__main__\":\n",
    "-    print(\"Hello, let's chat!\")print(more\n",
    "\\ No newline at end of file\n",
    "+    print(\"Hello, let's chat!\")print(moreprint('happy messages')\n",
    "\\ No newline at end of file\n",
    "\n",
    "````\n",
    "\n",
    "#### Nombres de branches\n",
    "\n",
    "Es común poner un prefijo/nombre según el tipo de branch.\n",
    "\n",
    "- Feature - feature/happy-bot\n",
    "\n",
    "- Fix - fix/remove-error\n",
    "\n",
    "- Chore - chore/add-analytics\n",
    "\n",
    "Features es para añadir funcionalidades.\n",
    "\n",
    "Fixes resuelven errores y similar.\n",
    "\n",
    "Chores son cosas que el usuario no percibe pero sirve para hacer el código más eficiente o reorganizar el proyecto.\n",
    "\n",
    "Así es más fácil ver las diferencias sabiendo qué hace cada cosa al usar git diff.\n",
    "\n",
    "\n",
    "````\n",
    "cd /home/dq/chatbot\n",
    "git checkout -b feature/random-messages\n",
    "printf \"\\nimport random\\nmessages=['Hi', 'Hi.', 'How are you?', 'Today is a long day...']\\nn=random.randint(1,len(messages)-1)\\nprint(messages[n])\" >> bot.py\n",
    "git add bot.py\n",
    "git commit -m \"Added random messaging to the bot!\"\n",
    "git push origin feature/random-messages\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos varios trabajando en un mismo proyecto y cada uno sacamos una branch del master en un mismo punto.\n",
    "\n",
    "Uno hace merge tras modificar un archivo. Ahora el master tiene un commit más\n",
    "\n",
    "![title](imagenes/merge_conflict_2.png)\n",
    "\n",
    "Y la historia de commits queda tal que así:\n",
    "\n",
    "![title](imagenes/merge_conflict_3.png)\n",
    "\n",
    "Si ahora yo trato de hacer merge o me va adejar porque ambos hemos modificado el mismo lugar. Git no va a sobreescribir nada si hay conflicto de commits. Si el commit 782 estuviera detrás del 45g no habría conflicto.\n",
    "\n",
    "Creando un conflicto:\n",
    "\n",
    "\n",
    "````\n",
    "cd ~\n",
    "git clone /dataquest/user/git/chatbot\n",
    "cd chatbot\n",
    "git checkout -b feature/king-bot\n",
    "printf \"\\nprint('I am the king')\" >> bot.py\n",
    "git add .\n",
    "git commit -m \"Make more kinglike\"\n",
    "git checkout master\n",
    "git checkout -b feature/queen-bot\n",
    "printf \"\\nprint('I am the queen')\" >> bot.py\n",
    "git add .\n",
    "git commit -m \"Make more queenlike\"\n",
    "git checkout master\n",
    "git merge feature/king-bot\n",
    "git merge feature/queen-bot\n",
    "````\n",
    "\n",
    "Cuando se hace un merge y hay conflicto, Git añade unas marcas en las líneas problemáticas del archivo con conflictos.\n",
    "\n",
    "Esto hará que no pueda ejecutarse, entre otras cosas.\n",
    "\n",
    "Para resolver este problema hay que abortar el merge\n",
    "\n",
    "````\n",
    "git merge --abort\n",
    "````\n",
    "\n",
    "También sirve para deshacer el último merge si ha sido por accidente o si interesa.\n",
    "\n",
    "Así se resetea el wd y la historia al estado anterior al merge.\n",
    "\n",
    "El aspecto del mensaje de conflicto en el archivo tiene este aspecto:\n",
    "\n",
    "````\n",
    "<<<<<<< HEAD                                                                    \n",
    "print('I am the king')                                                          \n",
    "=======                                                                         \n",
    "print('I am the queen')                                                          \n",
    ">>>>>>> feature/queen-bot\n",
    "\n",
    "````\n",
    "\n",
    "\n",
    "Si lo eliminamos manualmente en el master y dejamos el código deseado podemos hacer push normalmente:\n",
    "\n",
    "````\n",
    "cd /home/dq/chatbot\n",
    "git merge feature/queen-bot\n",
    "echo \"print('I am the queen')\" > bot.py\n",
    "git add bot.py\n",
    "git commit -m \"Fixed conflicts\"\n",
    "git push origin master\n",
    "\n",
    "````\n",
    "\n",
    "Cuando el conflicto tiene múltiples líneas se incluyen todas dentro de un mismo área marcada en el archivo conflictivo.\n",
    "\n",
    "````\n",
    "\n",
    "<<<<<<< HEAD                                                                    \n",
    "for i in range(0,3):\n",
    "    print(\"Off with his head!\")                                                          \n",
    "=======                                                                         \n",
    "print(\"Hello\")\n",
    "print(\"Off with your head!\")                                                         \n",
    ">>>>>>> feature/queen-bot \n",
    "for i in range(4,20):\n",
    "    print(\"This is the {0}th time I've complimented you!\".format(i))\n",
    "\n",
    "````\n",
    "\n",
    "Hay herramientas gráficas muy útiles para resolver los conflictos.\n",
    "\n",
    "Para ver cuáles están disponibles:\n",
    "\n",
    "````\n",
    "git mergetool --tool-help\n",
    "````\n",
    "\n",
    "Y suele salir algo como esto:\n",
    "\n",
    "````\n",
    "bc\n",
    "        bc3\n",
    "        codecompare\n",
    "        deltawalker\n",
    "        diffmerge\n",
    "        diffuse\n",
    "        ecmerge\n",
    "        emerge\n",
    "        examdiff\n",
    "        gvimdiff\n",
    "        gvimdiff2\n",
    "        gvimdiff3\n",
    "        kdiff3\n",
    "        meld\n",
    "        opendiff\n",
    "        p4merge\n",
    "        tkdiff\n",
    "        tortoisemerge\n",
    "        vimdiff\n",
    "        vimdiff2\n",
    "        vimdiff3\n",
    "        winmerge\n",
    "        xxdiff\n",
    "````\n",
    "\n",
    "\n",
    "Para ejecutar una específica:\n",
    "\n",
    "\n",
    "\n",
    "````\n",
    "git mergetool --tool=[tool name]\n",
    "\n",
    "````\n",
    "\n",
    "\n",
    "Esta es DiffMerge\n",
    "\n",
    "![title](imagenes/DiffMerge.png)\n",
    "\n",
    "Algunas solo funcionan en entornos de ventanas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cuando una branch tiene los cambios \"correctos\"\n",
    "\n",
    "Si sabemos qué cambios queremos conservar y están todos en una branch podemos hacer uso de:\n",
    "\n",
    "````\n",
    "git checkout --ours [filename]\n",
    "git checkout --theirs [filename]\n",
    "\n",
    "````\n",
    "\n",
    "ours sería la master o hacia donde estemos haciendo el merge. \n",
    "\n",
    "theis sería la branch de la que que se está haciendo merge.\n",
    "\n",
    "Para aplicarlo a todos los archivos:\n",
    "````\n",
    "git checkout --ours .\n",
    "\n",
    "````\n",
    "\n",
    "Funciona igual para el add anets de hacer commits\n",
    "````\n",
    "\n",
    "git add .\n",
    "````\n",
    "\n",
    "Ejemplo de conflicto resuelto con esto:\n",
    "\n",
    "````\n",
    "\n",
    "cd ~\n",
    "cd chatbot\n",
    "git checkout -b feature/remove-bot\n",
    "git rm bot.py\n",
    "git commit -m \"Remove bot\"\n",
    "git checkout master\n",
    "git checkout -b feature/keep-bot\n",
    "printf \"\\nprint('I want to live')\" >> bot.py\n",
    "git add .\n",
    "git commit -m \"Keep the bot around\"\n",
    "git checkout master\n",
    "git merge feature/remove-bot\n",
    "git merge feature/keep-bot\n",
    "git checkout --theirs .\n",
    "git add .\n",
    "git commit -m \"Keeping bot.py\"\n",
    "git push origin master\n",
    "\n",
    "````\n",
    "\n",
    "NOTA: para hacer un commit de la eliminación de un archivo se hace git rm archivo. Como en el ejemplo anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ignorar archivos\n",
    "\n",
    "Hay archivos que cambian muy frecuentemente y no son muy útiles para un proyecto.\n",
    "\n",
    "Por ejemplo .DS_Store y los archivos con extension .pyc. No son necesarios para que el proyecto funcione, sin embargo, cambian y pueden generear conflictos.\n",
    "\n",
    "La mejor manera de actuar es ingnorarlos para que Git no los añada a sus commits.\n",
    "\n",
    "PAra ello hay un fichero llamado .gitignore. Añadimos líneas que indican a Git qué ignorar. Acepta wildcards.\n",
    "\n",
    "\n",
    "````\n",
    "cd ~\n",
    "cd chatbot\n",
    "git checkout master\n",
    "printf \".DS_Store\\n*.pyc\" > .gitignore\n",
    "git add .gitignore\n",
    "git commit -m \"Added gitignore\"\n",
    "git push origin master\n",
    "````\n",
    "\n",
    "NOTA IMPORTANTE:\n",
    "\n",
    "Aunque hayamos añadido esas líneas a .gitignore,e sto no elimina los archivos que ya habíamos añadido a un commit anterior.\n",
    "\n",
    "Git aún seguirá verificando cambios en estos archivos y añadiendolos a futuros commits y causará conflictos.\n",
    "\n",
    "Hay que eliminar los archivos del Git cache para que sean invisibles en el trackeo de Git\n",
    "\n",
    "````\n",
    "git rm --cached .DS_Store\n",
    "````\n",
    "O por ejemplo otro archivo cualquiera\n",
    "\n",
    "````\n",
    "cd ~\n",
    "cd chatbot\n",
    "git checkout master\n",
    "git rm --cached bot.py\n",
    "git commit -m \"Removed bot.py\"\n",
    "git push origin master\n",
    "\n",
    "````\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalación de Git\n",
    "\n",
    "Descargar instalador e instalar\n",
    "\n",
    "En Terminal comprobar\n",
    "\n",
    "````\n",
    "git version\n",
    "````\n",
    "\n",
    "#### Configurar\n",
    "````\n",
    "git config --global user.name \"YOUR NAME\"\n",
    "\n",
    "git config --global user.email \"YOUR EMAIL ADDRESS\"\n",
    "\n",
    "````\n",
    "\n",
    "#### Registrarse en GitHub\n",
    "\n",
    "Seguir instrucciones\n",
    "\n",
    "#### Configurar ssh o https"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark and Map-Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map Reduce es un paradigma para distribuir cálculos eficientemente sobre cientos o miles de ordenadores.\n",
    "\n",
    "Hadoop es un pryecto open source que ha sido dominante para big data. Consiste en un sistema de ficheros HDFS (Hadoop Distributed File System) con su proopia impelentación de Map Reduce.\n",
    "\n",
    "Hadoop depende demasiado de almacenamiento en disco más que en memoria. Requiere pasos de escritura y lectura en disco y lo hace difícil para utilizar en data analysis interactivo.\n",
    "\n",
    "No tiene buen soporte de SQL y machine Learning. El menor precio de la RAM hace que Hadoop sea desplazado.\n",
    "\n",
    "Apache Spark depende de las estructuras de datos en la memoria, por lo que es mucho más rápido. [Spark](https://spark.apache.org/research.html)\n",
    "\n",
    "LA estructura de datos central de Spark es un Resilient Distributed Data Set (RDD). Es un data set distribuido a lo largo de la RAM de un cluster de máquinas. Es una colección de elementos que se puede usar para contener listas de tuplos, diccionarios, listas, etc.. similar a pandas datafreame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark\n",
    "\n",
    "Spark está en Scala (compila a bytecode desde la JVM). Pero han desarrolado un toolkit llamado PySpark para interacturar con RDDs desde Python con la librería Py4J."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\adrig\\\\spark-3.0.3-bin-hadoop2.7'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['YEAR\\tGoogleKnowlege_Occupation\\tShow\\tGroup\\tRaw_Guest_List',\n",
       " '1999\\tactor\\t1/11/99\\tActing\\tMichael J. Fox',\n",
       " '1999\\tComedian\\t1/12/99\\tComedy\\tSandra Bernhard',\n",
       " '1999\\ttelevision actress\\t1/13/99\\tActing\\tTracey Ullman',\n",
       " '1999\\tfilm actress\\t1/14/99\\tActing\\tGillian Anderson']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = sc.textFile(\"daily_show.tsv\")\n",
    "raw_data.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El SparkContext gestina la cinexión con los clusters y coordina sus procesamientos. Conecta los cluster managers. Los cluster managers controlan los executors que calculan.\n",
    "\n",
    "![title](imagenes/spark_context.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El RDD object es raw_data, que es como una string de objetos. Un objeto por cada línea.\n",
    "\n",
    "[Documentación de PySpark](https://spark.apache.org/docs/1.1.1/api/python/pyspark.rdd.RDD-class.html#take)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La implementacion de RDD de Spark permite la evaluación **lazy** del código, que pospone el cálculo hasta que sea necesario. Se pueden crear colas de tareas y dejar que Spark optimice en el background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipelining\n",
    "\n",
    "Cada operación en spak es una serie de pasos que se pueden encadenar y ejecutar en sucesión, forman una pipeline.\n",
    "\n",
    "Cada paso devuelve una cosa de las siguientes:\n",
    "\n",
    "- un valor (integer,..)\n",
    "- data structure (dict,..)\n",
    "- objeto RDD\n",
    "\n",
    "\n",
    "#### Función Map()\n",
    "\n",
    "map(f) aplica la f a todos los elementos del RDD. Los RDDs son iterables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['YEAR', 'GoogleKnowlege_Occupation', 'Show', 'Group', 'Raw_Guest_List'],\n",
       " ['1999', 'actor', '1/11/99', 'Acting', 'Michael J. Fox'],\n",
       " ['1999', 'Comedian', '1/12/99', 'Comedy', 'Sandra Bernhard'],\n",
       " ['1999', 'television actress', '1/13/99', 'Acting', 'Tracey Ullman'],\n",
       " ['1999', 'film actress', '1/14/99', 'Acting', 'Gillian Anderson']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_show = raw_data.map(lambda line: line.split('\\t'))\n",
    "daily_show.take(5)\n",
    "# Hit run to see the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La verdadera potencia de PySpark es que tiene la velocidad de Scala pero podemos aplicar python para nuestra interacción."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformations and Actions\n",
    "\n",
    "Hay dos tipos de métodos en Spark:\n",
    "\n",
    "1. Transformations — map(), reduceByKey()\n",
    "2. Actions — take(), reduce(), saveAsTextFile(), collect()\n",
    "\n",
    "\n",
    "Trasnformations son lazy operations que siemrpe devuelven una referencia a un objeto RDD. No las ejecuta hasta que una acción necesita una transformación.\n",
    "\n",
    "Cualquier función que devuelve un RDD es una transformación.\n",
    "\n",
    "Cualquier función que devuelva un valor es una acción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Immutability\n",
    "\n",
    "Los objetos RDD son inmutables, no pueden cambiar una vez creados.\n",
    "\n",
    "En Python, listas, dics son mutables mientras que los objetos tuplo son inmutables. Solo se pueden modificar creando uno nuevo modificado.\n",
    "\n",
    "Spark usa la inmutabilidad para mejorar la velocidad de cálculo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo\n",
    "\n",
    "Queremos contar el número de invitados cada año en el DaylyShow.\n",
    "\n",
    "Con python sería:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PipelinedRDD' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21520/2159687852.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtally\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdaily_show\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m   \u001b[0myear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0myear\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtally\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtally\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtally\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'PipelinedRDD' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "tally = dict()\n",
    "for line in daily_show:\n",
    "  year = line[0]\n",
    "  if year in tally.keys():\n",
    "    tally[year] = tally[year] + 1\n",
    "  else:\n",
    "    tally[year] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con Spark sería usando un Map y un ReduceBykey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PythonRDD[11] at RDD at PythonRDD.scala:53\n"
     ]
    }
   ],
   "source": [
    "tally = daily_show.map(lambda x: (x[0], 1)).reduceByKey(lambda x,y: x+y)\n",
    "print(tally)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que ha hecho es:\n",
    "\n",
    "- Durante el map se ha usado una lambda para crear un tuplo con key: x[0] y value: 1. Qudando algo así\n",
    "\n",
    "````\n",
    "('YEAR', 1)\n",
    "('1991', 1)\n",
    "('1991', 1)\n",
    "('1991', 1)\n",
    "('1991', 1)\n",
    "...\n",
    "\n",
    "````\n",
    "\n",
    "- Con ReduceByKey hacemos que quede algo así. Combina los tuplos con la misma key y ejecuta la f que pongas\n",
    "\n",
    "````\n",
    "('YEAR', 1)\n",
    "('1991', 4)\n",
    "...\n",
    "````\n",
    "\n",
    "Para ver el esultado de esos dos pasos se usa el comando take, que ejecuta el código lazy.\n",
    "\n",
    "En las RDD no se puede usar len, se usa count()\n",
    "\n",
    "````\n",
    "tally.take(tally.count())\n",
    "\n",
    "````\n",
    "\n",
    "Dando como reultado:\n",
    "\n",
    "````\n",
    "[('YEAR', 1),\n",
    " ('1999', 166),\n",
    " ('2000', 169),\n",
    " ('2001', 157),\n",
    " ('2002', 159),\n",
    " ('2003', 166),\n",
    " ('2004', 164),\n",
    " ('2005', 162),\n",
    " ('2006', 161),\n",
    " ('2007', 141),\n",
    " ('2008', 164),\n",
    " ('2009', 163),\n",
    " ('2010', 165),\n",
    " ('2011', 163),\n",
    " ('2012', 164),\n",
    " ('2013', 166),\n",
    " ('2014', 163),\n",
    " ('2015', 100)]\n",
    "\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter\n",
    "\n",
    "A diferencia de pandas, los RDD no tienen llos headers controlados. EN el ejemplo anterior shabría que quitar la priemra línea, pero los RDD son inmutables.\n",
    "\n",
    "Para crear un RDD nuevo con un criterio determinado a partir de otro RDD se puede usar la función filter(f), que devuelve un booleano según f se aplique en cada línea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filter_year(line):\n",
    "    if line[0] != 'YEAR':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "filtered_daily_show = daily_show.filter(lambda line: filter_year(line))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo de pipeline\n",
    "\n",
    "In the following code cell, we'll filter out professions for which the occupation is blank, lowercase each profession, generate a histogram of professions, and output the first five tuples in the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('actor', 596),\n",
       " ('film actress', 21),\n",
       " ('model', 9),\n",
       " ('stand-up comedian', 44),\n",
       " ('actress', 271)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_daily_show.filter(lambda line: line[1] != '') \\\n",
    "                   .map(lambda line: (line[1].lower(), 1)) \\\n",
    "                   .reduceByKey(lambda x,y: x+y) \\\n",
    "                   .take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark instalation and Jupyter Nb integration\n",
    "\n",
    "Se puede usar Spark de dos maneras:\n",
    "- Local mode: the entire Spark application runs on a single machine. You'll use local mode to prototype Spark code on your own computer. (This is the easier setup.)\n",
    "- Cluster mode: the Spark application runs across multiple machines. You'll use cluster mode when you want to run your Spark application across multiple machines in a cloud environment like Amazon Web Services, Microsoft Azure, or Digital Ocean.\n",
    "\n",
    "![title](imagenes/spark.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es necesario tener instalado el JDK versión 7 o posterior.\n",
    "COmporbar con comando\n",
    "````\n",
    "java -version\n",
    "\n",
    "````\n",
    "tiene que salir parecido a\n",
    "\n",
    "````\n",
    "java version \"1.7.0_79\"\n",
    "Java(TM) SE Runtime Environment (build 1.7.0_79-b15)\n",
    "Java HotSpot(TM) 64-Bit Server VM (build 24.79-b02, mixed mode)\n",
    "````\n",
    "\n",
    "[instalar spark e integrar con nb](https://naomi-fridman.medium.com/install-pyspark-to-run-on-jupyter-notebook-on-windows-4ec2009de21f)\n",
    "\n",
    "[otra guía de instalación](https://medium.com/big-data-engineering/how-to-install-apache-spark-2-x-in-your-pc-e2047246ffc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Rank,Major_code,Major,Total,Men,Women,Major_category,ShareWomen,Sample_size,Employed,Full_time,Part_time,Full_time_year_round,Unemployed,Unemployment_rate,Median,P25th,P75th,College_jobs,Non_college_jobs,Low_wage_jobs'],\n",
       " ['1,2419,PETROLEUM ENGINEERING,2339,2057,282,Engineering,0.120564344,36,1976,1849,270,1207,37,0.018380527,110000,95000,125000,1534,364,193'],\n",
       " ['2,2416,MINING AND MINERAL ENGINEERING,756,679,77,Engineering,0.101851852,7,640,556,170,388,85,0.117241379,75000,55000,90000,350,257,50'],\n",
       " ['3,2415,METALLURGICAL ENGINEERING,856,725,131,Engineering,0.153037383,3,648,558,133,340,16,0.024096386,73000,50000,105000,456,176,0'],\n",
       " ['4,2417,NAVAL ARCHITECTURE AND MARINE ENGINEERING,1258,1123,135,Engineering,0.107313196,16,758,1069,150,692,40,0.050125313,70000,43000,80000,529,102,0'],\n",
       " ['5,2405,CHEMICAL ENGINEERING,32260,21239,11021,Engineering,0.341630502,289,25694,23170,5180,16697,1672,0.061097712,65000,50000,75000,18314,4440,972'],\n",
       " ['6,2418,NUCLEAR ENGINEERING,2573,2200,373,Engineering,0.144966965,17,1857,2038,264,1449,400,0.177226407,65000,50000,102000,1142,657,244'],\n",
       " ['7,6202,ACTUARIAL SCIENCE,3777,2110,1667,Business,0.441355573,51,2912,2924,296,2482,308,0.095652174,62000,53000,72000,1768,314,259'],\n",
       " ['8,5001,ASTRONOMY AND ASTROPHYSICS,1792,832,960,Physical Sciences,0.535714286,10,1526,1085,553,827,33,0.021167415,62000,31500,109000,972,500,220'],\n",
       " ['9,2414,MECHANICAL ENGINEERING,91227,80320,10907,Engineering,0.119558903,1029,76442,71298,13101,54639,4650,0.057342278,60000,48000,70000,52844,16384,3253']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find path to PySpark.\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# Import PySpark and initialize SparkContext object.\n",
    "import pyspark\n",
    "sc = pyspark.SparkContext()\n",
    "\n",
    "# Read `recent-grads.csv` in to an RDD.\n",
    "f = sc.textFile('recent-grads.csv')\n",
    "data = f.map(lambda line: line.split('\\n'))\n",
    "data.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\adrig\\\\spark-3.0.3-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations and Actions\n",
    "\n",
    "[Spark Core](https://spark.apache.org/docs/latest/api/python/reference/pyspark.html)\n",
    "\n",
    "Leemos un text entero de Hamlet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hamlet@0\\t\\tHAMLET',\n",
       " 'hamlet@8',\n",
       " 'hamlet@9',\n",
       " 'hamlet@10\\t\\tDRAMATIS PERSONAE',\n",
       " 'hamlet@29']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_hamlet = sc.textFile('hamlet.txt')\n",
    "raw_hamlet.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada línea tiene string separadas por \\t. Habría que separar cada línea en strings independientes para quie sea más  manejable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_hamlet = raw_hamlet.map(lambda line: line.split('\\t'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAs lambda son útiles pero no suficeintes con funciones más complejas.\n",
    "\n",
    "PySpark permite definir funciones y pasarlas. Cualquier función que devuelve una secuencia de datos en PySpark requiere un **yield**.\n",
    "\n",
    "[Explicación de yield y generadores](https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do/231855#231855).\n",
    "\n",
    "En resumen yield es una técnica que permite generar datos necesarios (generator) sin tener que crear una lista entera de datos (interable) y guardarla en memoria.\n",
    "\n",
    "Spark ejecuta la función en cada elemento del RDD y restringe el scope.\n",
    "\n",
    "No todas las funciones requieren yield. map() o filter() usan return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### flatMap()\n",
    "\n",
    "Es diferente a map() en que no requiere un output en cada eleemnto del RDD. Es útil cuando se quiere generar una secuencia de valores desde un RDD.\n",
    "\n",
    "En este ejemplo queremos las líneas del RDD en las que HAMLET habla y asociamos la id de l la línea con un texto que indica que habla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hamlet@0', 'hamlet speaketh!'),\n",
       " ('hamlet@75', 'hamlet speaketh!'),\n",
       " ('hamlet@1004', 'hamlet speaketh!'),\n",
       " ('hamlet@9144', 'hamlet speaketh!'),\n",
       " ('hamlet@12313', 'hamlet speaketh!'),\n",
       " ('hamlet@12434', 'hamlet speaketh!'),\n",
       " ('hamlet@12760', 'hamlet speaketh!'),\n",
       " ('hamlet@12858', 'hamlet speaketh!'),\n",
       " ('hamlet@14821', 'hamlet speaketh!'),\n",
       " ('hamlet@15261', 'hamlet speaketh!')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def hamlet_speaks(line):\n",
    "    id = line[0]\n",
    "    speaketh = False\n",
    "    \n",
    "    if \"HAMLET\" in line:\n",
    "        speaketh = True\n",
    "    \n",
    "    if speaketh:\n",
    "        yield id,\"hamlet speaketh!\"\n",
    "\n",
    "hamlet_spoken = split_hamlet.flatMap(lambda x: hamlet_speaks(x))\n",
    "hamlet_spoken.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### filter()\n",
    "\n",
    "En este ejemplo hacemos lo mismo pero extrayendo las líneas enteras que dice Hamlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hamlet@0', '', 'HAMLET'],\n",
       " ['hamlet@75', 'HAMLET', 'son to the late, and nephew to the present king.'],\n",
       " ['hamlet@1004', '', 'HAMLET'],\n",
       " ['hamlet@9144', '', 'HAMLET'],\n",
       " ['hamlet@12313',\n",
       "  'HAMLET',\n",
       "  '[Aside]  A little more than kin, and less than kind.']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filter_hamlet_speaks(line):\n",
    "    if 'HAMLET' in line:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "hamlet_spoken_lines = split_hamlet.filter(lambda line: filter_hamlet_speaks(line))\n",
    "hamlet_spoken_lines.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count()\n",
    "\n",
    "Cuenta el número de elementos del RDD\n",
    "\n",
    "\n",
    "#### Collect()\n",
    "\n",
    "Devuelkve una lista de todfos los elementos del RDD. Es bueno para jugar con python sin PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spoken_count = 0\n",
    "spoken_101 = list()\n",
    "spoken_count = hamlet_spoken_lines.count()\n",
    "spoken_collect = hamlet_spoken_lines.collect()\n",
    "spoken_101 = spoken_collect[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381\n",
      "['hamlet@58478', 'HAMLET', 'A goodly one; in which there are many confines,']\n"
     ]
    }
   ],
   "source": [
    "print(spoken_count)\n",
    "print(spoken_101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentación PySpark\n",
    "\n",
    "- [PySpark's documentation for the RDD data structure] (https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.RDD.html#pyspark.RDD)\n",
    "- [Visual representation of methods (IPython Notebook format)](https://nbviewer.org/github/jkthompson/pyspark-pictures/blob/master/pyspark-pictures.ipynb)\n",
    "- [Visual representation of methods (PDF format)](https://training.databricks.com/visualapi.pdf)\n",
    "\n",
    "El último es muy bueno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge: Transformr Hamlet into a Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quitar el hamlet@ del id del elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', '', 'HAMLET'],\n",
       " ['8'],\n",
       " ['9'],\n",
       " ['10', '', 'DRAMATIS PERSONAE'],\n",
       " ['29'],\n",
       " ['30'],\n",
       " ['31', 'CLAUDIUS', 'king of Denmark. (KING CLAUDIUS:)'],\n",
       " ['74'],\n",
       " ['75', 'HAMLET', 'son to the late, and nephew to the present king.'],\n",
       " ['131']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_hamlet = sc.textFile(\"hamlet.txt\")\n",
    "split_hamlet = raw_hamlet.map(lambda line: line.split('\\t'))\n",
    "split_hamlet.take(5)\n",
    "\n",
    "\n",
    "def format_id(x):\n",
    "    id = x[0].split('@')[1]\n",
    "    results = list()\n",
    "    results.append(id)\n",
    "    if len(x) > 1:\n",
    "        for y in x[1:]:\n",
    "            results.append(y)\n",
    "    return results\n",
    "\n",
    "hamlet_with_ids = split_hamlet.map(lambda line: format_id(line))\n",
    "hamlet_with_ids.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora solo dejamos líneas con texto y eliminamos también los espacios en blanco ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', 'HAMLET'],\n",
       " ['10', 'DRAMATIS PERSONAE'],\n",
       " ['31', 'CLAUDIUS', 'king of Denmark. (KING CLAUDIUS:)'],\n",
       " ['75', 'HAMLET', 'son to the late, and nephew to the present king.'],\n",
       " ['132', 'POLONIUS', 'lord chamberlain. (LORD POLONIUS:)'],\n",
       " ['177', 'HORATIO', 'friend to Hamlet.'],\n",
       " ['204', 'LAERTES', 'son to Polonius.'],\n",
       " ['230', 'LUCIANUS', 'nephew to the king.'],\n",
       " ['261', 'VOLTIMAND', '|'],\n",
       " ['273', '|']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamlet_with_ids.take(5)\n",
    "\n",
    "real_text = hamlet_with_ids.filter(lambda line: len(line) > 1)\n",
    "hamlet_text_only = real_text.map(lambda line: [l for l in line if l != ''])\n",
    "hamlet_text_only.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora quitamos las pipe characters | donde estén solas y donde estén entre palabras sustituyendo por un caracter vacío"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', 'HAMLET'],\n",
       " ['10', 'DRAMATIS PERSONAE'],\n",
       " ['31', 'CLAUDIUS', 'king of Denmark. (KING CLAUDIUS:)'],\n",
       " ['75', 'HAMLET', 'son to the late, and nephew to the present king.'],\n",
       " ['132', 'POLONIUS', 'lord chamberlain. (LORD POLONIUS:)'],\n",
       " ['177', 'HORATIO', 'friend to Hamlet.'],\n",
       " ['204', 'LAERTES', 'son to Polonius.'],\n",
       " ['230', 'LUCIANUS', 'nephew to the king.'],\n",
       " ['261', 'VOLTIMAND'],\n",
       " ['273']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def fix_pipe(line):\n",
    "    results = list()\n",
    "    for l in line:\n",
    "        if l == \"|\":\n",
    "            pass\n",
    "        elif \"|\" in l:\n",
    "            fmtd = l.replace(\"|\", \"\")\n",
    "            results.append(fmtd)\n",
    "        else:\n",
    "            results.append(l)\n",
    "    return results\n",
    "\n",
    "clean_hamlet = hamlet_text_only.map(lambda line: fix_pipe(line))\n",
    "clean_hamlet.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Está inspirado en el dataframe de Pandas. Es una propiedad que permite crear y trabajar con datframes.\n",
    "\n",
    "Combina la escala y velocidad de Spark con la flexibilidad de pandas.\n",
    "\n",
    "Spark puede correr en memora distribuida y tiene mejor soporte para varios formatos de datos. Se puede usar una interfaz de SQL para hacer queries distribuidas de datasets muy grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"females\": 1994141, \"total\": 4079669, \"males\": 2085528, \"age\": 0, \"year\": 2010}\n",
      "\n",
      "{\"females\": 1997991, \"total\": 4085341, \"males\": 2087350, \"age\": 1, \"year\": 2010}\n",
      "\n",
      "{\"females\": 2000746, \"total\": 4089295, \"males\": 2088549, \"age\": 2, \"year\": 2010}\n",
      "\n",
      "{\"females\": 2002756, \"total\": 4092221, \"males\": 2089465, \"age\": 3, \"year\": 2010}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('census_2010.json')\n",
    "\n",
    "for i in range(0,4):\n",
    "    print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark SQL class\n",
    "\n",
    "Es una clase muy potente. Le da a Spark más información sobre la estructura de datos que se está usando y las computaciones que queremos.\n",
    "\n",
    "PAra ello utiliza un objeto SQLCOntext para estructurar los datos como DataFRame ne vez de SparkContext.\n",
    "\n",
    "Se puede hacer queries de un Spark DataFrame con SQL.\n",
    "\n",
    "Esta clase permite leer datos y crear nuevos df desde gran variedad de formatos ([Data Sources API](https://databricks.com/blog/2015/01/09/spark-sql-data-sources-api-unified-data-access-for-the-spark-platform.html)).\n",
    "\n",
    "\n",
    "##### File Formats\n",
    "\n",
    "- JSON, CSV/TSV, XML\n",
    "- Parquet, Amazon S3 (cloud storage service)\n",
    "\n",
    "##### Big Data Systems\n",
    "\n",
    "- Hive, Avro, HBase\n",
    "\n",
    "##### SQL Database Systems\n",
    "\n",
    "- MySQL, PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# Import SQLContext\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "# Pass in the SparkContext object `sc`\n",
    "sqlCtx = SQLContext(sc)\n",
    "\n",
    "# Read JSON data into a DataFrame object `df`\n",
    "df = sqlCtx.read.json(\"census_2010.json\")\n",
    "\n",
    "# Print the type\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se leen datos en un SQLContext object:\n",
    "- Instantiates a Spark DataFrame object\n",
    "- Infers the schema from the data and associates it with the DataFrame\n",
    "- Reads in the data and distributes it across clusters (if multiple clusters are available)\n",
    "- Returns the DataFrame object\n",
    "\n",
    "Tiene un sistema de tipos similar a pandas. Itera dos veces sobre losd atos: una para extraer la estructura de las columnas y otra para inferir el tipo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- females: long (nullable = true)\n",
      " |-- males: long (nullable = true)\n",
      " |-- total: long (nullable = true)\n",
      " |-- year: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay muchos métodos que se encuentran en pandas y en spark df, entre ellos:\n",
    "- agg()\n",
    "- join()\n",
    "- sort()\n",
    "- where()    \n",
    "\n",
    "A diferencia de pandas, os df de spark son inmutables para facilitar el trabajo en estructuras de datos distribuidas.\n",
    "\n",
    "EN pandas un df se construye con series y en spark con RDDs. Se pueden aplicar la mayoira de las mismas transformaciones, pero cambian estilos y métodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+-------+----+\n",
      "|age|females|  males|  total|year|\n",
      "+---+-------+-------+-------+----+\n",
      "|  0|1994141|2085528|4079669|2010|\n",
      "|  1|1997991|2087350|4085341|2010|\n",
      "|  2|2000746|2088549|4089295|2010|\n",
      "|  3|2002756|2089465|4092221|2010|\n",
      "|  4|2004366|2090436|4094802|2010|\n",
      "+---+-------+-------+-------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En pandas head() devuelve las priemras n filas. En Spark devuelve una liste de objetos fila.\n",
    "\n",
    "Spark devuelve objetos fila en head(), collect() y take() entre otros métodos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_one = df.head(5)[0]\n",
    "# Access value for age\n",
    "row_one.age\n",
    "# Access the first value\n",
    "row_one[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "first_five = df.head(5)\n",
    "for r in first_five:\n",
    "    print(r.age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También se pueden utilziar corchetes, pero tiene que ser una ista incluso cuando solo es una columna.\n",
    "\n",
    "En vez de corchetes se puede utilizar el método select().\n",
    "\n",
    "En cualquier caso solo se mostrará cuando se llame a show() ppor el lazy loading de spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "| 10|\n",
      "| 11|\n",
      "| 12|\n",
      "| 13|\n",
      "| 14|\n",
      "| 15|\n",
      "| 16|\n",
      "| 17|\n",
      "| 18|\n",
      "| 19|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---+-------+-------+\n",
      "|age|  males|females|\n",
      "+---+-------+-------+\n",
      "|  0|2085528|1994141|\n",
      "|  1|2087350|1997991|\n",
      "|  2|2088549|2000746|\n",
      "|  3|2089465|2002756|\n",
      "|  4|2090436|2004366|\n",
      "|  5|2091803|2005925|\n",
      "|  6|2093905|2007781|\n",
      "|  7|2097080|2010281|\n",
      "|  8|2101670|2013771|\n",
      "|  9|2108014|2018603|\n",
      "| 10|2114217|2023289|\n",
      "| 11|2118390|2026352|\n",
      "| 12|2132030|2037286|\n",
      "| 13|2159943|2060100|\n",
      "| 14|2195773|2089651|\n",
      "| 15|2229339|2117689|\n",
      "| 16|2263862|2146942|\n",
      "| 17|2285295|2165852|\n",
      "| 18|2285990|2168175|\n",
      "| 19|2272689|2159571|\n",
      "+---+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[['age']].show()\n",
    "\n",
    "df[['age','males','females']].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: bigint, males: bigint]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark DataFrame\n",
    "df.select('age')\n",
    "df.select('age', 'males')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boolean Filering in Spark DF\n",
    "\n",
    "Conserva la misma funcionalidad que en pandas. Incluso se debe poner la columna en el df sin el doble corchete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+-------+----+\n",
      "|age|females|  males|  total|year|\n",
      "+---+-------+-------+-------+----+\n",
      "|  6|2007781|2093905|4101686|2010|\n",
      "|  7|2010281|2097080|4107361|2010|\n",
      "|  8|2013771|2101670|4115441|2010|\n",
      "|  9|2018603|2108014|4126617|2010|\n",
      "| 10|2023289|2114217|4137506|2010|\n",
      "| 11|2026352|2118390|4144742|2010|\n",
      "| 12|2037286|2132030|4169316|2010|\n",
      "| 13|2060100|2159943|4220043|2010|\n",
      "| 14|2089651|2195773|4285424|2010|\n",
      "| 15|2117689|2229339|4347028|2010|\n",
      "| 16|2146942|2263862|4410804|2010|\n",
      "| 17|2165852|2285295|4451147|2010|\n",
      "| 18|2168175|2285990|4454165|2010|\n",
      "| 19|2159571|2272689|4432260|2010|\n",
      "| 20|2151448|2259690|4411138|2010|\n",
      "| 21|2140926|2244039|4384965|2010|\n",
      "| 22|2133510|2229168|4362678|2010|\n",
      "| 23|2132897|2218195|4351092|2010|\n",
      "| 24|2135789|2208905|4344694|2010|\n",
      "| 25|2136497|2197148|4333645|2010|\n",
      "+---+-------+-------+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "five_plus = df[df['age'] > 5]\n",
    "five_plus.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-------+-------+----+\n",
      "|age|females|  males|  total|year|\n",
      "+---+-------+-------+-------+----+\n",
      "|  0|1994141|2085528|4079669|2010|\n",
      "|  1|1997991|2087350|4085341|2010|\n",
      "|  2|2000746|2088549|4089295|2010|\n",
      "|  3|2002756|2089465|4092221|2010|\n",
      "|  4|2004366|2090436|4094802|2010|\n",
      "|  5|2005925|2091803|4097728|2010|\n",
      "|  6|2007781|2093905|4101686|2010|\n",
      "|  7|2010281|2097080|4107361|2010|\n",
      "|  8|2013771|2101670|4115441|2010|\n",
      "|  9|2018603|2108014|4126617|2010|\n",
      "| 10|2023289|2114217|4137506|2010|\n",
      "| 11|2026352|2118390|4144742|2010|\n",
      "| 12|2037286|2132030|4169316|2010|\n",
      "| 13|2060100|2159943|4220043|2010|\n",
      "| 14|2089651|2195773|4285424|2010|\n",
      "| 15|2117689|2229339|4347028|2010|\n",
      "| 16|2146942|2263862|4410804|2010|\n",
      "| 17|2165852|2285295|4451147|2010|\n",
      "| 18|2168175|2285990|4454165|2010|\n",
      "| 19|2159571|2272689|4432260|2010|\n",
      "+---+-------+-------+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df[df['males'] > df['females']].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convertir Spark DF en Pandas\n",
    "\n",
    "Como e suna librería relativamente nueva, le faltan algunas herramientas como histogramas y line plots.\n",
    "\n",
    "Se puede convertir a pandas df. Para da sets grandes habrá que hacerlo con subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pandas_df = df.toPandas()\n",
    "\n",
    "pandas_df['total'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de hacer queries de SQL hay que decirle a Spark que trate al df como una tabla SQL.\n",
    "\n",
    "Spark mantiene una data base virtual en el SQLContext object. A este objeto accedemos con sqlCtx y tiene sus métodos para registrar tablas temporales.\n",
    "\n",
    "Para guardar un df como tabla se usa el método registerTempTable() en el df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['census2010']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlCtx = SQLContext(sc)\n",
    "df = sqlCtx.read.json(\"census_2010.json\")\n",
    "\n",
    "df.registerTempTable('census2010')\n",
    "\n",
    "tables = sqlCtx.tableNames()\n",
    "\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora la tabla está registrada en nuestro sqlCtx y se puede emepzar a ahcer queries.\n",
    "\n",
    "En Spark SQL una query es una string que se pasa al método sql() del SQLContext object.\n",
    "\n",
    "El resultado de la query es un df object, pro lo que hay que usar show() para mostrar los resultados.\n",
    "\n",
    "SQLite necesita ; al final, pero Spark SQL da error si se pone ;. Es la única diferencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|age|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "| 10|\n",
      "| 11|\n",
      "| 12|\n",
      "| 13|\n",
      "| 14|\n",
      "| 15|\n",
      "| 16|\n",
      "| 17|\n",
      "| 18|\n",
      "| 19|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlCtx.sql('select age from census2010').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las queries de Spark DF o pandas son rápdias para coonsultas simples, pero si se quieren utilizar criterios más complejos es más simplé y rápido hacer queries en SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|  males|females|\n",
      "+-------+-------+\n",
      "|2093905|2007781|\n",
      "|2097080|2010281|\n",
      "|2101670|2013771|\n",
      "|2108014|2018603|\n",
      "|2114217|2023289|\n",
      "|2118390|2026352|\n",
      "|2132030|2037286|\n",
      "|2159943|2060100|\n",
      "|2195773|2089651|\n",
      "+-------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = 'select males, females from census2010 where age > 5 and age < 15'\n",
    "\n",
    "sqlCtx.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo mejor es que se pueden combinar fácilemte Spark df y SQL, ya que las queries de SQL devuelven un df object sobre el que se puede aplicar cualquier método de spark df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+\n",
      "|summary|             males|          females|\n",
      "+-------+------------------+-----------------+\n",
      "|  count|               101|              101|\n",
      "|   mean|1520095.3168316833|1571460.287128713|\n",
      "| stddev|  818587.208016823|748671.0493484351|\n",
      "|    min|              4612|            25673|\n",
      "|    max|           2285990|          2331572|\n",
      "+-------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = 'select males, females from census2010'\n",
    "\n",
    "sqlCtx.sql(query).describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join tables\n",
    "\n",
    "Algo muy potente es que spark lee cualquier tipo y fromato en df object y liego se pueden guardar como tablas para queries con SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['census1980', 'census1990', 'census2000', 'census2010', 'census_1980', 'census_1990', 'census_2000']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlCtx = SQLContext(sc)\n",
    "df = sqlCtx.read.json(\"census_2010.json\")\n",
    "df.registerTempTable('census2010')\n",
    "\n",
    "df_1980 = sqlCtx.read.json(\"census_1980.json\")\n",
    "df_1980.registerTempTable('census1980')\n",
    "\n",
    "df_1990 = sqlCtx.read.json(\"census_1990.json\")\n",
    "df_1990.registerTempTable('census1990')\n",
    "\n",
    "df_2000 = sqlCtx.read.json(\"census_2000.json\")\n",
    "df_2000.registerTempTable('census2000')\n",
    "\n",
    "\n",
    "tables = sqlCtx.tableNames()\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|  total|  total|\n",
      "+-------+-------+\n",
      "|4079669|3733034|\n",
      "|4085341|3825896|\n",
      "|4089295|3904845|\n",
      "|4092221|3970865|\n",
      "|4094802|4024943|\n",
      "|4097728|4068061|\n",
      "|4101686|4101204|\n",
      "|4107361|4125360|\n",
      "|4115441|4141510|\n",
      "|4126617|4150640|\n",
      "|4137506|4152174|\n",
      "|4144742|4145530|\n",
      "|4169316|4139512|\n",
      "|4220043|4138230|\n",
      "|4285424|4137982|\n",
      "|4347028|4133932|\n",
      "|4410804|4130632|\n",
      "|4451147|4111244|\n",
      "|4454165|4068058|\n",
      "|4432260|4011192|\n",
      "+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    " select census2010.total, census2000.total\n",
    " from census2010\n",
    " inner join census2000\n",
    " on census2010.age=census2000.age\n",
    "\"\"\"\n",
    "\n",
    "sqlCtx.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las funciones y operadores de SQLite están disponibles en SpqrkSQL\n",
    "\n",
    "- COUNT()\n",
    "- AVG()\n",
    "- SUM()\n",
    "- AND\n",
    "- OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+\n",
      "|sum(total)|sum(total)|sum(total)|\n",
      "+----------+----------+----------+\n",
      "| 312247116| 284594395| 254506647|\n",
      "+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    " select sum(census2010.total), sum(census2000.total), sum(census1990.total)\n",
    " from census2010\n",
    " inner join census2000\n",
    " on census2010.age=census2000.age\n",
    " inner join census1990\n",
    " on census2010.age=census1990.age\n",
    "\"\"\"\n",
    "sqlCtx.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
